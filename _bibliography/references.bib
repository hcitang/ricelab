
@inproceedings{graham2016sharedreflection,
  Abstract={Dramatic advances in sensor and computing miniaturization for personal data collection are making Personal Informatics (PI) tools a reality. Yet, advances in data collection have not been matched with similar advances in tools to promote, support, and facilitate reflection on this data. This gap leaves people with large swaths of data, but very little understanding of how to make sense of the data or to derive actionable insights. In this work, we explore a process called shared reflection, where individuals are paired with other data collectors, and asked (through prompts) to reflect on one another’s data. Based on a six-week study where 15 participants collected different kinds of personal data and engaged in a shared reflection process, we show that participants gained transformative insights from others’ reflections on their data. While this was promising, we discuss practical challenges in deploying this idea into real world personal informatics tools. In particular, while shared reflection can be appropriated to effectively bootstrap reflection on one’s data, this needs to be balanced against privacy and control concerns. },
  Author={Graham, Lisa and Tang, Anthony and Neustaedter, Carman},
  Booktitle={GROUP '16: Proceedings of the 18th International Conference on Supporting Group Work, Sanibel Island, FL, USA, November 09 - 12, 2014},
  Keywords={Shared reflection; personal informatics; personal data analytics; reflection.},
  Pdfurl={http://hcitang.org/papers/2016-group2016-sharedreflection.pdf},
  Title={Help Me Help You: Shared Reflection for Personal Data},
  Type={conference},
  Year={2016},
}

@mastersthesis{graham2016thesis,
  author       = {Graham, Lisa}, 
  title        = {Help Me Help You: Shared Reflection for Personal Data},
  school       = {University of Calgary},
  year         = {2016},
  month        = {05},
  abstract = {
  Although our ability to collect personal information has increased dramatically through personal
informatics tools such as personal digital tracking technologies for step counts, location, and
more, minimal attention has been paid to designing tools to generate actionable insight from
data. Self-reflection is important to generate these insights; however, without scaffolding to
support the process, it is often ineffective. In this thesis, I introduce and explore shared reflection
– the reciprocal process of reflecting on others’ data and having others reflect on one’s own data
– as a means to bootstrap the reflection process. I synthesize literature on personal informatics
and social learning theories, design and conduct a six-week personal data collection study, and
evaluate the results. Shared reflection appears to show promise; however, users value privacy
and control over their personal data when sharing in a social context. Finally, the potential
application of shared reflection to new personal informatics tools is explored. 
},
  Pdfurl={http://hcitang.org/papers/2016-mscthesis-graham.pdf},
  Type={thesis},
}

@mastersthesis{tang2015thesis,
  author       = {Tang, Richard}, 
  title        = {Physio at Home: Exploring Visual Guidance and Feedback
Techniques for At-home Rehabilitation},
  school       = {University of Calgary},
  year         = {2015},
  month        = {06},
  abstract = {
  Physiotherapy patients learn exercises for rehabilitation with the help of a physiotherapist, but
are at risk of re-injury while exercising alone at home. This thesis explores the design and usage
of visualizations for guiding patients through physiotherapy exercises at home. I interviewed a
practicing physiotherapist to gain knowledge on physiotherapy practices, and then developed a
set of visual characteristics for movement guidance: plane/range of movement, positions/angles
to maintain, extent of movement, and rate of movement. I applied these in the design of
movement-guiding visualizations in two prototype systems: Zipples and Physio@Home. Zipples
was a Microsoft Kinect-based prototype featuring robust movement recording and playback
functionality, supported by a variety of visualizations. Physio@Home was a Vicon-based
iteration that improved on Zipples with an annotation tool, an iteratively-designed Wedge
visualization, and multiple camera perspectives. I evaluated both systems with laboratory studies
to measure their effectiveness in having participants follow pre-recorded exercises. I conclude
with findings from both systems and studies, and discuss potential areas for future work.},
  Pdfurl={http://hcitang.org/papers/2015-mscthesis-tang.pdf},
  Type={thesis},
}

@inproceedings{alizadeh2016happyfeet,
  Abstract={We present HappyFeet, a dancing system designed for supporting dancing experience between remotely located dance partners. HappyFeet uses 3D representation of dancers’ feet in a shared virtual dance space to emphasize timing and placement of feet. It has two modes of operation: a learning mode where the user can dance with pre-recorded dance lessons, and a second mode where the system provides a shared dance floor for remotely located dancers. We evaluated our system in a laboratory study where we investigated the role of the feet embodiment by comparing its’ use to a video-only condition. The feet embodiment provided our participants with a better understanding of dance moves, helped them to synchronize timing of their dance steps, and provided them with a dance space in which they could freely create dance moves with their partners.},
  Author={Alizadeh, Hesam and Witcraft, Anna and Sharlin, Ehud and Tang, Anthony},
  Booktitle={GI '16: Proceedings of the 2016 Graphics Interface Conference},
  Title={HappyFeet: Embodiments for Joint Remote Dancing},
  Type={conference},
  Pdfurl={http://hcitang.org/papers/2016-gi2016-happyfeet.pdf},
  Videourl={http://hcitang.org/papers/2016-gi2016-happyfeet.mp4},
  Url={http://graphicsinterface.org/2016},
  Year={2016},
  Acceptance={13/33 - 39%},
}

@inproceedings{fakourfar2016annotations,
  Abstract={Recent mobile technology has provided new opportunities for creating remote assistance systems. However, mobile support systems present a particular challenge: both the camera and display are held by the user, leading to shaky video. When pointing or drawing annotations, this means that the desired target often moves, causing the gesture to lose its intended meaning. To address this problem, we investigate annotation stabilization techniques, which allow annotations to stick to their intended location. We studied two annotation systems, using three different forms of annotations, with both tablets and head-mounted displays. Our analysis suggests that stabilized annotations and head-mounted displays are only beneficial in certain situations. However, the simplest approach of automatically freezing video while drawing annotations was surprisingly effective in facilitating the completion of remote assistance tasks},
  Author={Fakourfar, Omid and Ta, Kevin and Tang, Richard and Bateman, Scott and Tang, Anthony},
  Booktitle={CHI 2016: Proceedings of the 2016 SIGCHI Conference on Human Factors in Computing Systems},
  Title={Stabilized Annotations for Mobile Remote Assistance},
  Type={conference},
  Pdfurl={http://hcitang.org/papers/2016-chi2016-annotations.pdf},
  Url={http://chi2016.acm.org/},
  Year={2016},
  Acceptance={23.4%},
}

@inproceedings{singhal2016bystanders,
  Abstract={We are observing an increase in the use of smartphones and wearable devices in public places for streaming and recording video. Yet the use of cameras in these devices can infringe upon the privacy of the people in the surrounding environment by inadvertently capturing them. This paper presents findings from an in-situ exploratory study that investigates bystanders’reactions and feelings towards streaming and recording videos with smartphones and wearable glasses in public spaces. We use the interview results to guide an exploration of design directions for mobile video.},
  Author={Singhal, Samarth and Neustaedter, Carman and Schiphorst, Thecla and Tang, Anthony and Abihisekh, Patra and Pan, Rui},
  Booktitle={EA CHI '16: Extended Abstracts of the 2016 SIGCHI Conference on Human Factors in Computing Systems},
  Keywords={Wearable glasses; privacy; streaming; recording.},
  Pdfurl={http://hcitang.org/papers/2016-chi2016wip-bystanders.pdf},
  Url={http://hcitang.org/papers/2016-chi2016wip-bystanders-poster.pdf},
  Title={You are Being Watched: Bystanders’ Perspective on the Use of Camera Devices in Public Spaces},
  Type={poster},
  Year={2016},
  Notes={6-page abstract + poster},
  Acceptance={281/647 - 43.4%},
}

@inproceedings{neustaedter2016mobiledevicesathome,
  Abstract={Mobile devices have begun to raise questions around the potential for overuse when in the presence of family or friends. As such, we conducted a diary and interview study to understand how people use mobile devices in the presence of others at home, and how this shapes their behavior and household dynamics. Results show that family members become frustrated when others do non-urgent activities on their phones in the presence of others. Yet people often guess at what others are doing because of the personal nature of mobile devices. In some cases, people developed strategies to provide a greater sense of activity awareness to combat the problem. Mobile phone usage was sometimes perceived as beneficial by providing a mechanism for needed disengagement from family members.  These findings suggest several opportunities for redesigning mobile device software to mitigate emergent frustrations, and open up new opportunities for nurturing social interactions among family members.
  },
  Author={Odour, Erick and Neustaedter, Carman and Odom, William and Tang, Anthony and Moallem, Niala and Tory, Melanie and Irani, Pourang},
  Booktitle={DIS 2016: Proceedings of the ACM conference on Designing Interactive Systems in 2016},
  Title={The Frustrations and Benefits of Mobile Device Usage in the Home when Co-Present with Family Members},
  Type={conference},
  Pdfurl={http://hcitang.org/papers/2016-dis2016-mobile-device-use-at-home.pdf},
  Url={http://www.dis2016.org/},
  Year={2016},
  Acceptance={108/418 - 26%},
  Notes={Honourable Mention - Top 5% of all submissions},
  Pages={1315-1327}
}

@inproceedings{jones2016dronevideoconferencing,
  Author={Jones, Brennan and Dillman, Kody and Tang, Richard and Tang, Anthony and Sharlin, Ehud and Oehlberg, Lora and Neustaedter, Carman and Bateman, Scott},
  Abstract={People are increasingly using mobile video to communicate, collaborate, and share experiences while on the go. Yet this presents challenges in adequately sharing camera views with remote users. In this paper, we study the use of semi-autonomous drones for video conferencing, where an outdoor user (using a smartphone) is connected to a desktop user who can explore the environment from the drone’s perspective. We describe findings from a study where pairs collaborated to complete shared navigation and search tasks. We illustrate the benefits of providing the desktop user with a view that is elevated, manipulable, and decoupled from the outdoor user. In addition, we articulate how participants overcame challenges in communicating environmental information and navigational cues, negotiated control of the view, and used the drone as a tool for sharing experiences. This provides a new way of thinking about mobile video conferencing where cameras that are decoupled from both users play an integral role in communication, collaboration, and sharing experiences.},
  Booktitle={DIS 2016: Proceedings of the ACM conference on Designing Interactive Systems in 2016},
  Title={Elevating Communication, Collaboration, and Shared Experiences in Mobile Video through Drones},
  Type={conference},
  Pdfurl={http://hcitang.org/papers/2016-dis2016-mobile-device-use-at-home.pdf},
  Url={http://www.dis2016.org/},
  Year={2016},
  Acceptance={108/418 - 26%},
  Pages={1123-1135}
}

@techreport{alizadeh2016culturalprobe,
  Abstract={ This report explores the question of how older adults understand and experience exercise (and physical activity) in their everyday lives. We provide this understanding by deploying a cultural probe study with seven participants in two local retirement communities. The result of our work is a set of design goals for a system to support remote activity.},
  Author={Alizadeh, Hesam and Witcraft, Anna and Sharlin, Ehud and Tang, Anthony},
  Title={ Exploring and Understanding Physical Activity Amoung Older Adults},
  Keywords={Physical activity, older adults, cultural probe study},
  Year={2015},
  Number={2015-1081-14},
  Publisher={Department of Computer Science, University of Calgary},
  Url={http://hdl.handle.net/1880/51025},
}

@incollection{huron2016constructivevis,
  Author={Huron, Samuel and Thudt, Alice and Aseniero, Bon Adriel and Tang, Anthony and Carpendale, Sheelagh},
  Abstract={In this chapter, with my collaborators, I provide a pictorial overview of two papers that address these challenges (Huron, Jansen, and Carpendale 2014; Huron, Carpendale, et al. 2014). In these paper we defne construction as a design paradigm for non-experts to author simple and dynamic visualizations. This paradigm is inspired by well-established theories in developmental psychological as well as past and existing practices of authoring visualization with tangible elements. We describe the simple conceptual components and processes underlying this paradigm and a preliminary study we employed to assess it. The results of this study confrm that non-experts in InfoVis can create, update, and annotate a visualization in a short period of time. Moreover, this study allowed us to articulate a primary model of how people perform the authoring of visual mappings using this paradigm.},
  Title={Constructive Visualization: A New Paradigm to Empower People to Author Visualization},
  Booktitle={SURFNET / Designing Digital Surface Applications},
  Editor={Maurer, Frank},
  Publisher={NSERC Surfnet, University of Calgary},
  URL={http://dspace.ucalgary.ca/handle/1880/50450},
  PDFUrl={http://hcitang.org/papers/2016-surfnet-constructive-visualization.pdf},
  Year={2016},
  Pages={169-191},
  Chapter={9},
  ISBN={978-0-88953-388-2},
}


@incollection{dillman2016athomephysiotherapy,
  Author={Dillman, Kody and Tang, Richard and Tang, Anthony},
  Abstract={ We are guided by three central questions in this work: first, what are the communication practices in traditional face-to-face physiotherapy that must be preserved; second, what challenges does video media space present to these practices, and third, how can technologies be designed to overcome these challenges? We explore these questions in this chapter through two explorations. In the first, we worked with physiotherapists to understand how to design tools to enable patients to work with physiotherapists live—for diagnosis and exercise training. In the second, we explored the ‘at-home’ case of doing exercises between physiotherapist visits. We make two contributions in this work. First, we provide insights into a specifc domain (physiotherapy) that can be used to guide design of video media spaces for remote work in this area. Second, from this work, we explore the concept of the body as a workspace, developing this idea through both sketches and critical refection of our experiences. Our ongoing work involves designing tools for effective remote physiotherapy, though the fndings should also support other domains where it is important to remotely teach activities that require specifc movements (e.g. dance, personal training, martial arts, etc.).},
  Title={Towards At-Home Physiotherapy: Next Generation Teleconferencing and Surface Based Interventions},
  Booktitle={SURFNET / Designing Digital Surface Applications},
  Editor={Maurer, Frank},
  Publisher={NSERC Surfnet, University of Calgary},
  URL={http://dspace.ucalgary.ca/handle/1880/50450},
  PDFUrl={http://hcitang.org/papers/2016-surfnet-towards-at-home-physio.pdf},
  Year={2016},
  Pages={289-304},
  Chapter={16},
  ISBN={978-0-88953-388-2},
}


@proceedings{gi2015,
  editor    = {Hao (Richard) Zhang and
               Anthony Tang},
  title     = {Proceedings of the 41st Graphics Interface Conference, Halifax, NS,
               Canada, June 3-5, 2015},
  publisher = {{ACM}},
  year      = {2015},
  url       = {http://dl.acm.org/citation.cfm?id=2788890},
  isbn      = {978-0-9947868-0-7},
  timestamp = {Mon, 15 Jun 2015 15:04:36 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/graphicsinterface/2015},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{marquardt2015excite,
  Abstract={A central issue in designing collaborative multi-surface environments is evaluating the interaction techniques, tools, and applications that we design. We often analyze data from studies using inductive video analysis, but this is extremely time-consuming because of the volume of data. We designed EXCITE, which gives analysts the ability to analyze studies by quickly querying aspects of people’s interactions with devices around them using a logical syntax. These queries provide simple, immediate visual access to matching incidents in the interaction stream, video data, and motion-capture data. The query language can help filter and review the data streams based on criteria such as distance or orientation between people and devices. This general approach allows analysts to provisionally develop theories and evaluate them rapidly, and aids the coding process for deeper analysis in the use of multi-surface environments.},
  Author={Marquardt, Nicolai and Schardong, Frederico and Tang, Anthony},
  Booktitle={INTERACT 2015: Proceedings of INTERACT 2015 - 16th IFIP TC 13 International Conference},
  Title={EXCITE: EXploring Collaborative Interaction in Tracked Environments},
  Type={conference},
  Pdfurl={http://hcitang.org/papers/2015-interact2015-excite.pdf},
  Url={http://www.interact2015.org/},
  Year={2015},
  Acceptance={29.6%},
  Pages={89--97},
}


@inproceedings{seyed2015ciphercard,
  Abstract={We present CipherCard, a physical token that defends against shoulder-surfing attacks on user authentication on capacitive touchscreen devices. When CipherCard is placed over a touchscreen’s pin-pad, it remaps a user’s touch point on the physical token to a different location on the pin-pad. It hence translates a visible user password into a different system password received by a touchscreen, but is hidden from observers as well as the user. CipherCard enhances authentication security through Two-Factor Authentication (TFA), in that both the correct user password and a specific card are needed for successful authentication. We explore the design space of CipherCard, and describe three implemented variations each with unique capabilities. Based on user feedback, we discuss the security and usability implications of CipherCard, and describe several avenues for continued exploration.},
  Author={Seyed, Teddy and Yang, Xing-Dong and Tang, Anthony and Greenberg, Saul and Gu, Jiawei and Zhu, Bin and Cao, Xiang},
  Booktitle={INTERACT 2015: Proceedings of INTERACT 2015 - 16th IFIP TC 13 International Conference},
  Pdfurl={http://hcitang.org/papers/2015-interact2015-ciphercard.pdf},
  Videourl={http://hcitang.org/papers/2015-interact2015-ciphercard.mov},
  Title={CipherCard: A Token-based Approach against Camera- based Shoulder Surfing Attacks on Common Touchscreen Devices},
  Type={conference},
  Url={http://www.interact2015.org/},
  Year={2015},
  Acceptance={26.8%},
  Pages={436--454},
}

@mastersthesis{aseniero2014thesis,
  author       = {Aseniero, Bon Adriel}, 
  title        = {STRATOS: The Design of Visualization to Support Decision-making in Software Release Planning},
  school       = {University of Calgary},
  year         = {2014},
  month        = {12},
  abstract = {
Software is typically developed in incremental stages or releases. Planning releases involves deciding on which features of the software should have implementation priority. This is a complex planning process involving numerous constraints and factors, trade-offs, that often make decisions difficult. Since the success of a product depends on this plan, it is vital for planners to examine the trade-offs between different alternatives in order to make an informed choice. To support this type of decision-making, my exploration involved designing and implementing STRATOS—a visualization tool showing several software release plans simultaneously within a singular layout, helping planners understand the differences among them. Through a qualitative evaluation, I found that it enabled a range of decision-making processes, ultimately helping participants in choosing an optimal release plan. My contributions include the hybrid visualization, STRATOS, and the findings from its evaluation that implicate design for future visualizations supporting decision-making.
  },
  Pdfurl={http://hcitang.org/papers/2014-mscthesis-aseniero.pdf},
  Type={thesis},
}

@mastersthesis{dunlap2013thesis,
  author       = {Dunlap, Matthew A.}, 
  title        = {Science Caching: Applying Geocaching to Mobile Citizen Science},
  school       = {University of Calgary},
  year         = {2013},
  month        = {5},
  abstract = {
  	Citizen science occurs in part when scientists work with volunteers to collect science data in particular field locations. The benefit is that citizen science eases and lessens the cost of collecting such information. Yet it has a variety of known problems. This document focuses on four specific citizen science problems concerning difficulties in data collection, data validation, volunteer training and volunteer coordination. The thesis is that these problems can be mitigated by applying aspects from another thriving location-based activity: the geocaching treasure hunt as enabled by mobile devices. Citizen science can exploit geocaching‘s location-based design, its use of physical objects, and its user maintained content. To explore and critique this thesis, a prototype mobile system called Science Caching was developed, along with various scenarios that describe how it addresses issues in collection, validation, training and coordination. The system and scenarios – which serve as a working sketch – were shown to citizen science experts via an interview-based design critique. In particular, they provided feedback on the choice of the problems addressed by the system, the approach to the problems as realized by Science Caching, how those approaches could be extended, and what other areas in citizen science they could be applied to. The results were analyzed via affinity diagramming, which uncovered various overarching themes. Generally, the combination of geocaching and mobility was received quite positively, where participants indicated various areas where it would be applicable. Problems and improvements were also suggested, giving insight into future iterations of the method and the system.
  },
  Pdfurl={http://hcitang.org/papers/2013-mscthesis-dunlap.pdf},
  Type={thesis},
}


@article{dunlap2015sciencecaching,
  Abstract={Site-based citizen science occurs when volunteers work with scientists to collect data at particular field locations. The benefit is greater data collection at lesser cost. Yet difficulties exist. We developed ScienceCaching, a prototype citizen science aid designed to mitigate four specific problems by applying aspects from another thriving location-based activity: geocaching as enabled by mobile devices. Specifically, to ease problems in data collection, ScienceCaching treats sites as geocaches: Volunteers find sites opportunistically via geocaching methods and use equipment and other materials pre-stored in cache containers. To ease problems in data validation, ScienceCaching flags outlier data as it is entered so that on-site volunteers can be immediately check and correct data. Additionally, other volunteers are directed to that site at a later time for further readings that provide data redundancy. To ease volunteer training, ScienceCaching directs volunteers to training sites on an as-needed basis, where they are taught and tested against known measures. To ease volunteer coordination, ScienceCaching automatically directs volunteers to particular sites of interest, and real-time communication between volunteers and scientist is enabled as needed. We developed ScienceCaching primarily as a technology probe—a working but quite limited system—to embody these ideas and to evaluate their worthiness by eliciting reactions from scientists involved in citizen science. Scientists saw many opportunities in using fixed location caches and geocaching techniques to aid citizen science. Yet they expanded the discussion. Amongst these, they emphasized practical concerns that must be addressed, and they argued that future systems should carefully consider the role of the social experience—both the “online” experience and the shared physical experience of visiting sites.},
  Author = {Dunlap, Matthew A. and Tang, Anthony and Greenberg, Saul},
  Journal = {Personal and Ubiquitous Computing},
  Year = {2015},
  Title = {Applying geocaching principles to site-based citizen science and eliciting reactions via a technology probe},
  Type = {journal},
  Doi={http://dx.doi.org/10.1007/s00779-015-0837-0},
  Pdfurl={http://hcitang.org/papers/2015-puc-sciencecaching.pdf},
  Pages = {897-913},
  Publisher = {Springer},
  Volume={19},
  Issue={5-6},
  ISSN={1617-4909},
}

@inproceedings{payne2015physvis,
  Abstract={Physical visualization has been demonstrated to be more efficient than on-screen representation for information visualization tasks [5]. In addition, it has been suggested that physical visualization might be particularly memorable or engaging [12], but this has yet to be explored empirically. This paper describes a potential evaluative study that would explore differences between flat, on-screen bar graphs and extruded bar graphs, a simple form of physical visualization. Specifically, memorability of information, user engagement, accuracy and efficiency of information retrieval using physical and on-screen graphs would be compared. Broader challenges and possibilities for the evaluation of physical visualization are discussed.},
  Author={Payne, Jennifer and Johnson, Jason and Tang, Anthony},
  Booktitle={Exploring the Challenges of Making Data Physical - Workshop at CHI 2015},
  Editor={Jason Alexander and Yvonne Jansen and Kasper Hornbaek and Johan Kildal and Abhijit Karnik},
  Pdfurl={http://hcitang.org/papers/2015-chi2015workshop-physvis.pdf},
  Title={Exploring Physical Visualization},
  Type={workshop},
  Url={http://www.scc.lancs.ac.uk/physicaldata2015/},
  Year={2015},
}

@inproceedings{jones2015mobilevideoconferencing,
  Abstract={Video conferencing allows people to collaborate and share experiences across a variety of work and play- related scenarios. Mobile video conferencing enables entirely new usage scenarios where one or more parties are physically moving around in a large activity environment. One major benefit of mobile devices is that they can potentially support activities that focus on large environments—activities such as searching, navigating, and touring. However, today’s mobile video conferencing tools are not designed to support such activities. We discuss potential design ideas for mobile video conferencing tools that could better support these kinds of activities.},
  Author={Jones, Brennan and Tang, Anthony},
  Booktitle={Everyday Telepresence: Emerging Practices and Future Research Directions - Workshop at CHI 2015},
  Editor={Irene Rae and Bilge Mutlu and Gary M. Olson and Judith S. Olson and Leila A. Takayama and Gina Venolia},
  Pdfurl={http://hcitang.org/papers/2015-chi2015workshop-mobile-video-conferencing.pdf},
  Title={Improving Collaboration and Shared Experiences in Out-and-About Mobile Video Conferencing},
  Type={workshop},
  Url={http://hci.cs.wisc.edu/workshops/chi2015/},
  Year={2015},
}

@inproceedings{witcraft2015asymmetry,
  Abstract={While there exist substantial efforts to support independent living among the elderly, a significant portion of this demographic will continue to require assisted living facilities. Many of the residents in these facilities may experience extreme feelings of loneliness and depression. Our interest is in addressing these feelings of loneliness. We report here on an early pilot study of a paper prototype for a communication system and our early insights from this process. Specifically, we discuss the asymmetry of desiring communication, the cost of interaction, the accessibility of tools and the topics of conversation.},
  Author={Witcraft, Anna and Tang, Anthony and Hushlak, Gerald},
  Booktitle={Smart for Life: Designing Smart Home Technologies that Evolve with Users- Workshop at CHI 2015},
  Editor={Sarah Mennicken and Amy Hwang and Rayoung Yang and Jesse Hoey and Alex Mihailidis and Elaine M. Huang},
  Pdfurl={http://hcitang.org/papers/2015-chi2015workshop-asymmetry-of-needs.pdf},
  Title={Asymmetry of Needs},
  Type={workshop},
  Url={http://www.zpac.ch/smartforlife/cfp.html},
  Year={2015},
}

@inproceedings{jones2015mobilecamerawork,
  Abstract={Mobile video conferencing, where one or more participants are out from behind a desk and moving about in the real world, enables entirely new interaction scenarios (for example, asking a remote party for help to construct or repair an object, or showing a physical location to someone). While we have a good understanding of the challenges of video conferencing in office or home environments, we do not fully understand the mechanics of camera work—how people use mobile devices to communicate with one another—during mobile video calls. To understand these mechanics, we conducted an observational study where pairs of participants completed tasks using a mobile video conferencing system. Our analysis suggests that people use the camera view deliberately to support their interactions—for example, to convey a message or to ask questions—but the limited field of view, and the lack of camera control can make it a frustrating experience for remote parties.},
  Author = {Jones, Brennan and Witcraft, Anna and Tang, Anthony and Bateman, Scott and Neustaedter, Carman},
  Booktitle = {CHI 2015: Proceedings of the 2015 SIGCHI Conference on Human Factors in Computing Systems},
  Doi = {http://dx.doi.org/10.1145/2702123.2702345},
  Title={Mechanics of Camera Work in Mobile Video Collaboration},
  Type={conference},
  Year={2015},
  PdfUrl={http://hcitang.org/papers/2015-chi2015-mobile-video-collaboration.pdf},
  VideoUrl={http://hcitang.org/papers/2015-chi2015-mobile-video-collaboration.mp4},
  Pages = {957-966},
  Publisher={ACM},
}

@inproceedings{tang2015physioathome,
  Abstract = {Physiotherapy patients exercising at home alone are at risk of re-injury since they do not have corrective guidance from a therapist. To explore solutions to this problem, we designed Physio@Home, a prototype that guides people through pre-recorded physiotherapy exercises using real-time visual guides and multi-camera views. Our design addresses several aspects of corrective guidance, including: plane and range of movement, positions and angles of joints to maintain, and extent of movement. We evaluated our design, comparing how closely participants could follow exercise movements in various feedback conditions. Participants were most accurate when using the visual guide and multi-views. Based on our qualitative findings on the visual complexity of the feedback, we conclude with suggestions for exercise guidance systems.},
  Author = {Tang, Richard and Yang, Xing-Dong and Tang, Anthony and Bateman, Scott and Jorge, Joaquim},
  Booktitle = {CHI 2015: Proceedings of the 2015 SIGCHI Conference on Human Factors in Computing Systems},
  Doi = {http://dx.doi.org/10.1145/2702123.2702401},
  Title={Physio@Home: Exploring visual guidance and feedback techniques for physiotherapy patients at home},
  Type={conference},
  Year={2015},
  Pdfurl={http://hcitang.org/papers/2015-chi2015-physio-at-home.pdf},
  Videourl={http://hcitang.org/papers/2015-chi2015-physio-at-home.mp4},
  Pages = {4123-4132},
  Publisher={ACM},
}

@inproceedings{aseniero2015stratos,
  Abstract = {Software is typically developed incrementally and released in stages. Planning these releases involves deciding which features of the system should be implemented for each release. This is a complex planning process involving numerous constraints and factors—trade-offs that often make decisions difficult. Since the success of a product depends on this plan, it is important to understand the trade-offs between different release plans and to make an informed choice. We present STRATOS, a tool that visualizes several optimized software release plans simultaneously. The visualization shows several attributes about each plan that are important to planners. Multiple plans are shown in a single layout to help planners find and understand the trade-offs between different plans. We evaluated our tool via a qualitative study, finding that STRATOS enables a range of decision-making processes, and ultimately helping our participants optimize their planning.},
  Author = { Aseniero, Bon Adriel and Wun, Tiffany and Ledo, David and Ruhe, Guenther and Tang, Anthony and Carpendale, Sheelagh },
  Booktitle = {CHI 2015: Proceedings of the 2015 SIGCHI Conference on Human Factors in Computing Systems},
  Title = {STRATOS: Using Visualization to Support Decisions in Strategic Software Release Planning},
  Doi={http://dx.doi.org/10.1145/2702123.2702426},
  Type={conference},
  Year={2015},
  Pdfurl={http://hcitang.org/papers/2015-chi2015-stratos.pdf},
  Videourl={http://hcitang.org/papers/2015-chi2015-stratos.mp4},
  Pages={1479-1488},
  Publisher={ACM},
}

@inproceedings{reilly2015mixedreality,
  Abstract = {We present results from a study examining how the physical layout of a project room and task affect the cognitive maps acquired of a connected virtual environment during mixed-presence collaboration. Results indicate that a combination of physical layout and task impacts cognitive maps of the virtual space. Participants did not form a strong model of how different physical work regions were situated relative to each other in the virtual world when the tasks performed in each region differed. Egocentric perspectives of multiple displays enforced by different furniture arrangements encouraged cognitive maps of the virtual world that reflected these perspectives, when the displays were used for the same task. These influences competed or coincided with document-based, audiovisual and interface cues, influencing collaboration. We consider the implications of our findings on WYSIWIS mappings between real and virtual for mixed-presence collaboration.},
  Author = { Reilly, Derek and Echenique, Andy and Wu, Andy and Tang, Anthony and Edwards, Keith},
  Booktitle = {CHI 2015: Proceedings of the 2015 SIGCHI Conference on Human Factors in Computing Systems},
  Title = {Mapping out Work in a Mixed Reality Project Room},
  Type={conference},
  Year={2015},
  Doi = {http://dx.doi.org/10.1145/2702123.2702506},
  Pdfurl = {http://hcitang.org/papers/2015-chi2015-mixed-reality.pdf},
  Pages = {887-896},
  Publisher={ACM},
}



@article{huang2015pva,
  Abstract={Data surrounds each and every one of us in our daily lives, ranging from exercise logs, to archives of our interactions with others on social media, to online resources pertaining to our hobbies. There is enormous potential for us to use these data to understand ourselves better and make positive changes in our lives. Visualization (Vis) and Visual Analytics (VA) offer substantial opportunities to help individuals gain insights about themselves, their communities and their interests; however, designing tools to support data analysis in non-professional life brings a unique set of research and design challenges. We investigate the requirements and research directions required to take full advantage of Vis and VA in a personal context. We develop a taxonomy of design dimensions to provide a coherent vocabulary for discussing Personal Visualization and Personal Visual Analytics. By identifying and exploring clusters in the design space, we discuss challenges and share perspectives on future research. This work brings together research that was previously scattered across disciplines. Our goal is to call research attention to this space and engage researchers to explore the enabling techniques and technology that will support people to better understand data relevant to their personal lives, interests, and needs.},
  Author = {Huang, Dandan and Tory, Melanie and Aseniero, Bon Adriel and Bartram, Lyn and Bateman, Scott and Carpendale, Stacey and Tang, Anthony and Woodbury, Robert},
  Journal = {IEEE Transactions on Visualization and Computer Graphics},
  Keywords = {Taxonomy, personal context, interaction design, mobile and ubiquitous visualization},
  Year = {2015},
  Pdfurl={http://hcitang.org/papers/2015-tvcg-pva.pdf},
  Title={Personal Visualization and Personal Visual Analytics},
  Type={journal},
  Doi={http://doi.ieeecomputersociety.org/10.1109/TVCG.2014.2359887},
  Pages={420-433},
  Volume={21},
  Issue={3},
  ISSN={1077-2626},
}

@inproceedings{jones2014spherosumo,
  Abstract={The Sphero is a robotic remote-controlled ball capable of rolling around on its own in any direction at multiple speeds. Numerous games have been designed for the Sphero for smartphones and tablets. However, most of these games provide an interface for controlling the Sphero that is far from natural. These games also do not put a strong focus on the physical environment around the Sphero. This work discusses a control scheme used to control a Sphero with another Sphero, and a pervasive game leveraging this scheme that emphasizes physical properties of the environment to create an immersive experience.},
  Author={Jones, Brennan and Dillman, Kody and Manesh, Setareh Aghel and Sharlin, Ehud and Tang, Anthony},
  Booktitle={EA CHI PLAY '14: ACM SIGCHI Annual Symposium on Computer-Human Interaction in Play},
  Keywords={Sphero; robotic ball; pervasive gaming; controllers; natural mappings; immersion; gaming experience},
  Pdfurl={http://hcitang.org/papers/2014-chiplay2014-spherosumo.pdf},
  Title={Designing an Immersive and Entertaining Pervasive Gameplay Experience with Spheros as Game and Interface Elements},
  Type={poster},
  Year={2014},
  Doi={http://dx.doi.org/10.1145/2658537.2661301},
  Notes={2-page abstract + poster}
}

@inproceedings{seyed2014exploring,
  author={Seyed, Teddy and Rodrigues, Francisco Marinho and Maurer, Frank and Tang,
    Anthony},
  title={Exploring 3D volumetric medical data using mobile devices},
  booktitle={3DUI 2014: 2014 IEEE Symposium on 3D User Interfaces},
  year={2014},
  pages={173-174},
  type={poster},
  publisher={IEEE},
  abstract={Medical imaging specialists have traditionally used keyboard and mouse
    based techniques and interfaces for examining both 2D and 3D medical images,
    but with newer imaging technologies resulting in significantly larger volumes
    of 3D medical images, these techniques that have become increasingly cumbersome
    for imaging specialists. To replace traditional techniques, using mobile devices
    present an effective means for navigating and exploring complex 3D medical
    data sets, as they provide increased fluidity and flexibility, leveraging people's
    existing skills with tangible objects. 3D interactions using mobile devices
    may provide benefit for imaging specialists, but little is known about using
    these interactions in the medical imaging domain. In this paper, we explore
    the design of 3D interaction techniques using mobile devices and preliminary
    feedback from imaging specialists suggests that these interactions may be a
    viable solution for the medical imaging domain.},
  pdfurl={http://hcitang.org/papers/2014-3duiposter-exploring-3d-volumetric-data.pdf},
  doi={http://dx.doi.org/10.1109/3DUI.2014.6798876}
}

@inproceedings{huron2014constructiveviz,
  Abstract={If visualization is to be democratized, we need to provide a means
    for non-experts to create visualizations that allow them to engage with datasets.
    We present constructive visualization as a new paradigm for the simple creation
    of flexible, dynamic visualizations. Constructive visualization is simple---that
    skills required to build and manipulate the visualizations are akin to kindergarten
    play; it is expressive---one can build within the constraints of the chosen
    environment, and it also supports dynamics as these visualizations can be rebuilt
    and adjusted. We describe the conceptual components and processes underlying
    constructive visualization, and describe real-world examples to illustrate
    the utility of this approach. The constructive visualization approach builds
    on our inherent understanding and experience with physical building blocks,
    the model enables non-experts to create entirely novel visualizations, and
    to engage with datasets in a manner that would not have otherwise been possible.},
  Acceptance={26{\%} - 105/402},
  Author={Huron, Samuel and Carpendale, Sheelagh and Thudt, Alice and Tang, Anthony
    and Mauerer, Michael},
  Booktitle={DIS 2014: Proceedings of the ACM conference on Designing Interactive
    Systems in 2014},
  Doi={http://dx.doi.org/10.1145/2598784.2598806},
  Keywords={Design; visualization; construction; assembling; constructivism; constructionism;
    education},
  Notes={Best Paper Nominee (top 2{\%} of submissions)},
  Pdfurl={http://hcitang.org/papers/2014-dis2014-constructive-visualization.pdf},
  Publisher={ACM},
  Title={Constructive Visualization},
  Type={conference},
  Year={2014},
  Bdsk-Url-1={http://dx.doi.org/10.1145/2598784.2598806},
  pages={433-442 }
}

@inproceedings{alizadeh2014haptics,
  Abstract={Group exercise provides motivation to follow and maintain a healthy
    daily exercise schedule while enjoying beneficial encouragement and social
    support from friends and exercise partners. However, mobility and transportation
    issues frequently prevent seniors from engaging in group activities. To address
    this problem, we investigated the exercise needs of seniors and developed a
    prototype remote exercise system. Our system uses haptic feedback to simulate
    assistive pushing and pulling of limbs when exercising with a partner, and
    we developed three distinct vibration metaphors -- constant push/pull, corrective
    feedback, and notification -- to convey engagement and connection between exercise
    partners. We conducted a preliminary evaluation of our system and our vibration
    metaphors to determine the validity of our design concepts. We contribute a
    set of lessons on the use of haptic feedback for remote group exercise.},
  Acceptance={49{\%} - 241/496},
  Author={Alizadeh, Hesam and Tang, Richard and Sharlin, Ehud and Tang, Anthony},
  Booktitle={CHI EA '14: CHI '14 Extended Abstracts on Human Factors in Computing
    Systems},
  Date-Added={2014-02-11 03:05:40 +0000},
  Date-Modified={2014-06-06 17:09:00 +0000},
  Doi={http://dx.doi.org/10.1145/2559206.2581318},
  Keywords={Exergame; Interpersonal Synchronization; Haptic feedback},
  Notes={6-page abstract + poster.},
  Pages={2401-2406},
  Pdfurl={http://hcitang.org/papers/2014-chi2014wip-remote-haptics.pdf},
  Publisher={ACM},
  Title={Haptics in Remote Collaborative Exercise Systems for Seniors},
  Type={poster},
  Url={http://hcitang.org/papers/2014-chi2014wip-remote-haptics-poster.pdf},
  Year={2014},
  Bdsk-Url-1={http://hcitang.org/papers/2014-chi2014wip-remote-haptics-poster.pdf},
  Bdsk-Url-2={http://dx.doi.org/10.1145/2559206.2581318}
}

@inproceedings{jones2014arttherapy,
  Abstract={Art therapy provides therapeutic benefit to people suffering from chronic
    pain, and recent work has explored supporting art therapy through online tools
    such as chat forums and discussion boards. These tools give people the benefit
    of engaging in art therapy without the burden of having to leave one's home
    (when transportation may be a challenge), and allowing people to reveal their
    identities through dialog and activity rather than through one's appearance.
    However, these tools also do not provide much opportunity for collaboration
    and shared art-making. Because group members are not aware of each other's
    actions and non-verbal cues in a chat room, they cannot collaborate with each
    other easily. We discuss the design and development of tools that promote enhanced
    awareness of non-verbal cues and shared creative experiences in online group
    art therapy.},
  Acceptance={49{\%} - 241/496},
  Author={Jones, Brennan and Hankinson, Sara Prins and Collie, Kate and Tang, Anthony},
  Booktitle={CHI EA '14: CHI '14 Extended Abstracts on Human Factors in Computing
    Systems},
  Date-Added={2014-02-11 03:04:14 +0000},
  Date-Modified={2014-06-06 17:08:47 +0000},
  Doi={http://dx.doi.org/10.1145/2559206.2581302},
  Keywords={Art therapy; online therapy; telehealth; art making; collaboration;
    user awareness; user representation},
  Notes={6-page abstract + poster.},
  Pages={1759-1764},
  Pdfurl={http://hcitang.org/papers/2014-chi2014wip-art-therapy.pdf},
  Publisher={ACM},
  Title={Supporting Non-Verbal Visual Communication in Online Group Art Therapy},
  Type={poster},
  Url={http://hcitang.org/papers/2014-chi2014wip-art-therapy-poster.pdf},
  Year={2014},
  Bdsk-Url-1={http://hcitang.org/papers/2014-chi2014wip-art-therapy.pdf},
  Bdsk-Url-2={http://dx.doi.org/10.1145/2559206.2581302}
}

@inproceedings{tang2014physioathome,
  Abstract={Patients typically undergo physiotherapy with the help of a physiotherapist,
    who teach, guide, and correct the patient as they perform exercises. The problem
    is when the patient is at home, without guidance and corrective feedback from
    a physiotherapist, the patient will not know if they are doing their exercises
    incorrectly. To address this problem, we implemented a prototype that guides
    patients through pre-recorded exercise movements using visual guides overlaid
    atop a mirror-view of the patient on a wall-mounted display. We conducted informal
    evaluations with pilot studies to evaluate our current designs. We identified
    some working designs and design characteristics, and in our pilot study, participants
    showed improvement in movement accuracy with the guides over recorded video.
    Collected data will assist in developing future iterations of the system and
    designing improved guides for physiotherapy instruction at home.},
  Acceptance={49{\%} - 241/496},
  Author={Tang, Richard and Alizadeh, Hesam and Tang, Anthony and Bateman, Scott
    and Jorge, Joaquim},
  Booktitle={CHI EA '14: CHI '14 Extended Abstracts on Human Factors in Computing
    Systems},
  Date-Added={2014-02-11 03:02:43 +0000},
  Date-Modified={2014-06-06 17:08:28 +0000},
  Doi={http://dx.doi.org/10.1145/2559206.2581197},
  Keywords={Physiotherapy; Human Factors; Design; Measurement},
  Notes={6-page abstract + poster.},
  Pages={1651-1656},
  Pdfurl={http://hcitang.org/papers/2014-chi2014wip-physio@home.pdf},
  Publisher={ACM},
  Title={Physio@Home: Design Explorations to Support Movement Guidance},
  Type={poster},
  Url={http://hcitang.org/papers/2014-chi2014wip-physio@home-poster.pdf},
  Year={2014},
  Bdsk-Url-1={http://hcitang.org/papers/2014-chi2014wip-physio@home-poster.pdf},
  Bdsk-Url-2={http://dx.doi.org/10.1145/2559206.2581197}
}

@inproceedings{seyed2014medical,
  Abstract={3D volumetric medical images, such as MRIs, are commonly explored and
    interacted with by medical imaging experts using systems that require keyboard
    and mouse-based techniques. These techniques have presented challenges for
    medical imaging specialists: 3D spatial navigation is difficult, in addition
    to the detailed selection and analysis of 3D medical images being difficult
    due to depth perception and occlusion issues. In this work, we explore a potential
    solution to these challenges by using tangible interaction techniques with
    a mobile device to simplify 3D interactions for medical imaging specialists.
    We discuss preliminary observations from our design sessions with medical imaging
    specialists and argue that tangible 3D interactions using mobile devices are
    viable solution for the medical imaging domain, as well as highlight that domain
    plays an important role in 3D interaction techniques. },
  Acceptance={49{\%} - 241/496},
  Author={Seyed, Teddy and Rodrigues, Francisco Marinho and Maurer, Frank and Tang,
    Anthony},
  Booktitle={CHI EA '14: CHI '14 Extended Abstracts on Human Factors in Computing
    Systems},
  Date-Added={2014-02-11 02:58:06 +0000},
  Date-Modified={2014-06-06 17:08:35 +0000},
  Doi={http://dx.doi.org/10.1145/2559206.2581301},
  Keywords={Mobile devices, medical imaging, 3D navigation, volumetric imaging},
  Notes={6-page abstract + poster.},
  Pages={2341-2346},
  Pdfurl={http://hcitang.org/papers/2014-chi2014wip-medical-imaging.pdf},
  Publisher={ACM},
  Title={Medical Imaging Specialists and 3D: A Domain Perspective on Mobile 3D
    Interactions},
  Type={poster},
  Url={http://hcitang.org/papers/2014-chi2014wip-medical-imaging-poster.pdf},
  Year={2014},
  Bdsk-Url-1={http://hcitang.org/papers/2014-chi2014wip-medical-imaging-poster.pdf},
  Bdsk-Url-2={http://dx.doi.org/10.1145/2559206.2581301}
}

@techreport{neustaedter2004interpersonalawareness,
  Address={Department of Computer Science, University of Calgary, Calgary, Alberta,
    Canada T2N 1N4},
  Author={Neustaedter, Carman and Elliot, Kathryn and Tang, Anthony and Greenberg,
    Saul},
  Date-Added={2014-01-24 04:02:35 +0000},
  Date-Modified={2014-01-24 04:04:07 +0000},
  Institution={University of Calgary},
  Keywords={Interpersonal awareness, ubiquitous groupware},
  Month={October},
  Number={2004-760-25},
  Pdfurl={http://dspace.ucalgary.ca/bitstream/1880/45886/2/2004-760-25.pdf},
  Title={Where Are You and When Are You Coming Home? Foundations of Interpersonal
    Awareness},
  Type={techreport},
  Url={http://hdl.handle.net/1880/45886},
  Year={2004},
  Publisher={Department of Computer Science, University of Calgary},
  Bdsk-Url-1={http://hdl.handle.net/1880/45886}
}

@techreport{tang2006reference,
  Address={Department of Computer Science, University of British Columbia, Vancouver,
    British Columbia, Canada V6T 1Z4},
  Annote={Usable digital tabletop design hinges on a deep understanding of people's
    natural work practices over traditional tables. We present an ethnographic
    study of engineering project teams that highlights the use of reference material---artifacts
    not the primary product or focus of work activity, but referred to or inspected
    while the work activity is carried out---in tabletop work. We show how the
    variety of reference material forms and their role in tabletop work suggest
    that digital tabletop systems must recognize external artifacts and should
    allow reconfiguration of external work surfaces and information. },
  Author={Tang, Anthony and Fels, Sid},
  Date-Added={2014-01-24 03:59:13 +0000},
  Date-Modified={2014-01-24 04:00:26 +0000},
  Institution={University of British Columbia},
  Keywords={Tabletop groupware, collaboration, reference material},
  Month={July},
  Number={TR-2008-08},
  Pdfurl={http://www.cs.ubc.ca/cgi-bin/tr/2006/TR-2006-05.pdf},
  Publisher={Department of Computer Science, University of British Columbia},
  Title={"What I Want, Where I Want:" Reference Material Use in Tabletop Work},
  Type={techreport},
  Url={http://www.cs.ubc.ca/cgi-bin/tr/2006/TR-2006-05},
  Year={2006},
  Bdsk-Url-1={http://www.cs.ubc.ca/cgi-bin/tr/2006/TR-2006-05}
}

@techreport{tang2008activityslittear,
  Abstract={In prior work, we introduced a visualization technique for analyzing
    fixed position video streams called slit-tear visualizations. This technique
    supports exploratory data analysis by interactively generating views about
    the video stream that can provide insight into the spatial/temporal relationships
    of the entities contained within. These insights are necessarily grounded in
    context of the specific video being analyzed, and in this paper, we provide
    a general typology of the kinds of slit-tears an analyst may use. Further,
    we discuss the kinds of analytic primitives that often signal relevant events
    given these slit-tear types. The work is relevant to human-centered computing
    because the technique provides the most insight in the presence of human interpretation.},
  Address={Department of Computer Science, University of British Columbia, Vancouver,
    British Columbia, Canada V6T 1Z4},
  Author={Tang, Anthony and Lanir, Joel and Greenberg, Saul and Fels, Sid},
  Date-Added={2014-01-24 03:56:26 +0000},
  Date-Modified={2014-01-24 03:58:49 +0000},
  Institution={University of British Columbia},
  Keywords={video analysis, exploratory data analysis, information visualization,
    video history},
  Month={July},
  Number={TR-2008-08},
  Pdfurl={http://www.cs.ubc.ca/cgi-bin/tr/2008/TR-2008-08.pdf},
  Publisher={Department of Computer Science, University of British Columbia},
  Title={Uncovering Activity and Patterns in Video using Slit-Tear Visualizations},
  Type={techreport},
  Url={http://www.cs.ubc.ca/cgi-bin/tr/2008/TR-2008-08},
  Year={2008},
  Bdsk-Url-1={http://www.cs.ubc.ca/cgi-bin/tr/2008/TR-2008-08}
}

@techreport{ledo2012onespace,
  Address={Department of Computer Science, University of Calgary, Calgary, Alberta,
    Canada T2N 1N4},
  Author={Ledo, David and Aseniero, Bon Adriel and Boring, Sebastian and Tang,
    Anthony},
  Date-Added={2014-01-24 03:50:40 +0000},
  Date-Modified={2014-01-24 03:51:43 +0000},
  Institution={University of Calgary},
  Month={December},
  Number={2012-1033-16},
  Title={OneSpace: Shared Depth-Corrected Video Interaction},
  Type={techreport},
  Year={2012},
  Publisher={Department of Computer Science, University of Calgary},
  PdfUrl={http://hcitang.org/papers/2012-tr-onespace-2012-1033-16.pdf}
}

@inproceedings{tang2005awarenessmpg,
  Abstract={Mixed presence groupware (MPG) is software that connects both collocated
    and distributed collaborators together in a shared visual workspace. Our early
    study of this new genre is that people focus their collaborative energy on
    collocated partners at the expense of remote partners, which imbalances collaboration.
    We call this problem presence disparity, caused by the imbalance of awareness
    exuded by virtual embodiments versus actual people. VideoArms is an embodiment
    technique that mitigates presence disparity by enhancing awareness of remote
    collaborators in a mixed presence workspace. We describe how VideoArms works,
    and the design principles behind its construction},
  Author={Tang, Anthony and Greenberg, Saul},
  Booktitle={Awareness Systems: Known Results, Theory, Concepts and Future Challenges
    - Workshop at CHI 2005},
  Date-Added={2014-01-22 04:45:45 +0000},
  Date-Modified={2014-01-22 04:49:06 +0000},
  Editor={Paulos Markopoulos and Boris De Ruyter and Wendy Mackay},
  Keywords={Mixed presence groupware, awareness, consequential communication, embodiments,
    gestures},
  Pdfurl={http://grouplab.cpsc.ucalgary.ca/papers/2005/05-WorkshopPapers.CHI/05-SupportingAwareness-Tang-Greenberg.pdf},
  Title={Supporting Awareness in Mixed Presence Groupware},
  Type={workshop},
  Url={http://www.awareness-research.org/WS_programme.html},
  Year={2005},
  Bdsk-Url-1={http://www.awareness-research.org/WS_programme.html}
}

@inproceedings{tang2006egocentric,
  Abstract={Instant messaging (IM) allows us to maintain relationships with our
    social network through messaging and status information. We present early iterations
    of visualizations of IM interactions that help to visually identify several
    different types of relationships, such as intimate socials, long-lost-friend,
    and asymmetric relationships. Our work is motivated by an interest in designing
    awareness systems that can help reflect or even affect our desired social relationships.},
  Author={Tang, Anthony and Neustaedter, Carman},
  Booktitle={Social Visualization: Exploring Text, Audio and Video Interactions},
  Date-Added={2014-01-22 04:44:44 +0000},
  Date-Modified={2014-01-22 04:45:35 +0000},
  Pdfurl={http://hcitang.org/papers/2006-chi2006-visualizing-social-relationships-in-im.pdf},
  Title={Visualizing Egocentric Relationships in Instant Messaging},
  Type={workshop},
  Url={http://social.cs.uiuc.edu/soc-viz.html},
  Year={2006},
  Bdsk-Url-1={http://social.cs.uiuc.edu/soc-viz.html}
}

@inproceedings{agrawala2006porn,
  Abstract={As an extreme case of browsing, the pornographic browsing experience
    has several unique UI characteristics: it requires simple, lightweight controls;
    usage needs to be discrete; users' mental and physical context need to be respected,
    and common, repeated interactions need to be supported. While we identify design
    goals for user interfaces to better support browsing of pornographic images
    and movies, the same goals are applicable to other non-controversial browsing
    activities},
  Author={Agrawala, Anand and Tang, Anthony and Greenberg, Saul},
  Booktitle={Sexual Interactions - Workshop at CHI 2006},
  Date-Added={2014-01-22 04:43:19 +0000},
  Date-Modified={2014-01-22 04:44:28 +0000},
  Editor={Joanna Brewer and Jofish Kaye and Amanda Williams and Susan Wyche},
  Pdfurl={http://hcitang.org/papers/2006-chi2006-browsing-porn.pdf},
  Title={Browsing Pornography: An Interface Design Perspective},
  Type={workshop},
  Url={http://www.ics.uci.edu/~johannab/sexual.interactions.2006/chi2006.sex.FRONT.htm},
  Year={2006},
  Bdsk-Url-1={http://www.ics.uci.edu/~johannab/sexual.interactions.2006/chi2006.sex.FRONT.htm}
}

@inproceedings{tang2008bystandersworkshop,
  Abstract={In this paper, we reflect on the design and deployment process of MAGICBoard,
    a public display deployed in a university setting that solicits the electronic
    votes and opinions of bystanders on trivial but amusing topics. We focus on
    the consequences of our design choices with respect to encouraging bystanders
    to interact with the public display. Bystanders are individuals around the
    large display who may never fully engage with the application itself, but are
    potential contributors to the system. Drawing on our recent experiences with
    MAGICBoard, we present a classification of bystanders, and then discuss three
    design themes relevant to the design of systems for bystander use: graduated
    proximal engagement, lowering barriers for interaction and supporting covert
    engagement.},
  Author={Tang, Anthony and Finke, Matthias and Blackstock, Michael and Leung,
    Rock and Deutscher, Meghan and Tain, Gavin and Giesbrecht Catherine},
  Booktitle={Designing and Evaluation Mobile Phone-based Interaction with Public
    Displays},
  Date-Added={2014-01-22 04:41:08 +0000},
  Date-Modified={2014-01-22 04:43:02 +0000},
  Editor={Corina Sas and Alan Dix},
  Pdfurl={http://hcitang.org/papers/2008-chi2008-workshop-design-for-bystanders.pdf},
  Title={Designing for Bystanders: Reflections on Building a Public Digital Forum},
  Type={workshop},
  Url={http://www.comp.lancs.ac.uk/~corina/CHI08Workshop/},
  Year={2008},
  Bdsk-Url-1={http://www.comp.lancs.ac.uk/~corina/CHI08Workshop/}
}

@inproceedings{tang2008fourlessons,
  Abstract={While many researchers are interested in developing and designing technologies
    for multiple-display environments (MDEs), a core problem remains: we do not
    fully understand the role these display technologies can play in real-world
    activities. Our approach has been to study traditional MDEs (i.e. offices and
    laboratory environments) to understand both the tasks supported by traditional
    displays, and the roles the displays play in these tasks. We discuss a set
    of lessons from studies of traditional displays, and discuss how designers
    of MDEs can learn from these lessons in their designs. In so doing, we contribute
    to the growing understanding of the potential role of MDEs in supporting real-world
    work, and MDE design.},
  Author={Tang, Anthony and Fels, Sid},
  Booktitle={Beyond the Laboratory: Supporting Authentic Collaboration with Multiple
    Displays - Workshop at CSCW 2008},
  Date-Added={2014-01-22 04:39:22 +0000},
  Date-Modified={2014-01-22 04:40:59 +0000},
  Editor={Jacob Biehl and Gene Golovchinsky and Kent Lyons},
  Pdfurl={http://hcitang.org/papers/2008-cscw2008-workshop-four-lessons-for-mdes.pdf},
  Title={Four Lessons from Traditional MDEs},
  Type={workshop},
  Url={http://workshops.fxpal.com/cscw2008/},
  Year={2008},
  Bdsk-Url-1={http://workshops.fxpal.com/cscw2008/}
}

@inproceedings{tang2010expressiveness,
  Abstract={In the broad design space of telepresence systems, we are interested
    in contexts where users collaborate over a shared workspace. Our work involving
    connecting distributed touch surfaces (e.g. distributed tabletops) has shed
    light on the problem of supporting reference space---the ability of collaborators
    to point at, and refer to objects in the workspace. A promising approach to
    support this gestural communication has been to capture video of users' arms
    as they work over the surface, transmitting and overlaying that video at remote
    workstations. The problem with this approach is that the video image is a flat
    projection of users' 3D bodies, limiting the expressiveness of users' gestures,
    and occasionally providing false information. In our most recent work, we have
    begun exploring {\^a}{\euro}?non-photorealistic{\^a}{\euro}? visualizations
    of users' bodies to support expressiveness in reference space.},
  Author={Tang, Anthony and Genest, Aaron and Shoemaker, Garth and Gutwin, Carl
    and Fels, Sid and Booth, Kellogg S.},
  Booktitle={New Frontiers in Telepresence - CSCW 2010 Workshop},
  Date-Added={2014-01-22 04:37:38 +0000},
  Date-Modified={2014-01-22 04:39:14 +0000},
  Editor={Gina Venolia and Kori Inkpen and Judith Olson and David Nguyen},
  Pdfurl={http://hcitang.org/papers/2010-cscw2010-workshop-expressiveness.pdf},
  Title={Enhancing Expressiveness in Reference Space},
  Type={workshop},
  Url={http://research.microsoft.com/en-us/events/nft2010/},
  Year={2010},
  Bdsk-Url-1={http://research.microsoft.com/en-us/events/nft2010/}
}

@inproceedings{lanir2010studentcontrol,
  Author={Lanir, Joel and Booth, Kellog S. and Tang, Anthony},
  Booktitle={EIST 2010: Next Generation of HCI and Education: Workshop on UI Technology and
    Education Pedagogy - Workshop at CHI 2010},
  PdfUrl={http://hcitang.org/papers/2010-eist2010-student-control.pdf},
  Date-Added={2014-01-22 04:32:57 +0000},
  Date-Modified={2014-01-22 04:36:48 +0000},
  Editor={Edward Tse and Johannes Sch{\"o}ning and Yvonne Rogers and Chia Shen
    and Gerald Morrison},
  Title={Enabling Student Control of a Classroom's Shared Screen},
  Type={workshop},
  Year={2010}
}

@inproceedings{tang2011interstitial,
  Abstract={Multi-display environments comprise large shared displays as well as
    personal devices. In this work, we discuss how the interstitial space---the
    space between displays and de- vices---can also be made into an interactive
    space. Such a space can support collaborative data analysis by providing a
    focus+context workspace; providing a means to transition between collaborative
    and individual work, and by provid- ing a means to transition tasks between
    devices.},
  Author={Tang, Anthony and Irani, Pourang},
  Booktitle={DEXIS 2011 Workshop on Data Exploration for Interaction Surfaces -
    Workshop at ITS 2011},
  Date-Added={2014-01-22 04:30:53 +0000},
  Date-Modified={2014-01-22 04:32:12 +0000},
  Editor={Petra Isenberg and Sheelagh Carpendale and Tobias Hesselmann and Tobias
    Isenberg and Bongshin Lee},
  Pdfurl={http://hcitang.org/papers/2012-dexis-interstitial-space.pdf},
  Title={Interstitial Space in MDEs for Data Analysis},
  Type={workshop},
  Url={http://www.aviz.fr/dexis2011/pmwiki.php},
  Year={2011},
  Bdsk-Url-1={http://www.aviz.fr/dexis2011/pmwiki.php}
}

@inproceedings{neustaedter2012mrgames,
  Author={Neustaedter, Carman and Moulder, Vicky and Wakkary, Ron and Judge, Tejinder
    and Tang, Anthony},
  Booktitle={Mixed Reality Games - Workshop at CSCW 2012},
  Date-Added={2014-01-22 04:28:47 +0000},
  Date-Modified={2014-01-22 04:30:27 +0000},
  Editor={Elizabeth Bonsignore and Derek L. Hansen and Zachary O. Toups and Lennart
    E. Nacke and Anastasia Salter and Wayne Lutters},
  Pdfurl={http://hcitang.org/papers/2012-cscw2012-workshop-designing-mixed-reality-games.pdf},
  Title={Designing Mixed Reality Games to Study Culture, Family Practices and Social
    Engagement},
  Type={workshop},
  Url={http://mixedrealitygames.selfloud.net/},
  Year={2012},
  Bdsk-Url-1={http://mixedrealitygames.selfloud.net/}
}

@inproceedings{genest2012expressivenessmatters,
  Abstract={Crisis command centres often gather data from disparate locations and
    collect it for visualization on a large, shared screen. However, the resulting
    visualization often lacks expressiveness: it fails to express nuanced mediating
    characteristics about the information, such as specificity, urgency, awareness,
    or reliability. We suggest that our previous work on creating expressive realtime
    embodiments can inform the design of crisis management embodiments on large
    displays, improving communication and decision-making. We make several recommendations
    for future research directions},
  Author={Genest, Aaron and Bateman, Scott and Tang, Anthony and Scott, Stacey
    and Gutwin, Carl},
  Booktitle={Collaboration and Crisis Informatics - Workshop at CSCW 2012},
  Date-Added={2014-01-22 04:26:38 +0000},
  Date-Modified={2014-01-22 04:28:31 +0000},
  Editor={Volkmar Pipek and Jonas Landgren and Leysia Palen},
  Pdfurl={http://hcitang.org/papers/2012-cscw2012-workshop-expressiveness-in-c-and-c.pdf},
  Title={Why Expressive Matters in Command and Control Visualizations},
  Type={workshop},
  Url={http://crisisinformatics.wineme.fb5.uni-siegen.de/},
  Year={2012},
  Bdsk-Url-1={http://crisisinformatics.wineme.fb5.uni-siegen.de/}
}

@inproceedings{reilly2011organicui,
  Author={Reilly, Derek and Tang, Anthony and Wu, Andy and Echenique, Andy and
    Massey, Jonathan and Mathiasen, Niels and Mazalek, Ali and Edwards, W. Keith},
  Booktitle={Second International Workshop on Organic User Interfaces at TEI 2011},
  Date-Added={2014-01-22 04:16:01 +0000},
  Date-Modified={2014-01-22 04:24:50 +0000},
  Editor={Audrey Girouard and Roel Vertegaal and Ivan Poupyrev},
  Title={Organic UIs in Cross-Reality Spaces},
  Type={workshop},
  Url={http://www.organicui.org/workshop},
  PdfUrl={http://hcitang.org/papers/2011-tei2011workshop-organic-cross-reality.pdf},
  Year={2011},
  Bdsk-Url-1={http://www.organicui.org/workshop}
}

@inproceedings{perteneder2012ideaplayground,
  Abstract={Creativity and innovation are much sought-after qualities of indi-
    viduals and organizations, but existing creativity practises are not cohesively
    integrated with digital workflows or digital artefacts. We introduce a set
    of design considerations for digital systems to support creative processes,
    specifically supporting the three ongo- ing, iterative activities of creative
    processes: gathering inspiration, generating ideas, and refining ideas. We
    present Idea Playground, a system built upon these considerations that supports
    diverse input sources, synchronous and asynchronous use, and freeform information
    structuring.},
  Author={Peterender, Florian and Grossauer, Christian and Seifried, Thomas and
    Walney, Jagoda and Brosz, John and Tang, Anthony and Carpendale, Sheelagh and
    Haller, Michael},
  Booktitle={Designing Collaborative Interactive Spaces - Workshop at AVI 2012},
  Date-Added={2014-01-18 23:42:38 +0000},
  Date-Modified={2014-01-18 23:47:01 +0000},
  Editor={Hans-Christian Jetter and Florian Geyer and Harald Reiterer and Raimund
    Dachselt and Gerhard Fischer and Rainer Groh and Michael Haller and Thomas
    Herrmann},
  Keywords={Design process, brainstorming, interactive environment, interactive
    surface, pen input, multi-user input},
  Pdfurl={http://hcitang.org/papers/2012-avi2012workshop-idea-playground.pdf},
  Title={Idea Playground: When Brainstorming is Not Enough},
  Type={workshop},
  Year={2012}
}

@inproceedings{grossauer2012mathsketch,
  Abstract={Traditional whiteboards are a common medium for mathematics education,
    and are particularly suited to the high school and college level where conceptual
    understanding of the subject matter is emphasized above procedural understanding.
    Although considerable work has been done to apply sketch-based interaction
    to mathematics learning, very few have addressed this from the perspective
    of teaching mathematics in a conventional classroom environment. We provide
    a set of design considerations for dynamic whiteboards in instructional contexts
    and present an embodiment of these considerations in our prototype, MathSketch.},
  Author={Grossauer, Christian and Perteneder, Florian and Haller, Michael and
    Walny, Jagoda and Brosz, John and Tang, Anthony and Carpendale, Sheelagh},
  Booktitle={EIST 2012: Educational Interfaces, Software and Technology - Workshop
    at CHI 2012},
  Date-Added={2014-01-18 23:28:38 +0000},
  Date-Modified={2014-01-18 23:41:44 +0000},
  Editor={Edward Tse and Lynn V. Marentette and Syed Ishtianque Ahmed and Alex
    Thayler and Jochen Huber and Max M{\"u}hlh{\"a}user and Si Jung "Jun" Kim and
    Quincy Brown},
  Keywords={Electronic whiteboards, mathematics, education, sketching, representation},
  Pdfurl={http://hcitang.org/papers/2012-chi2012workshop-mathsketch.pdf},
  Title={MathSketch: Designing a Dynamic Whiteboard for Instructional Contexts},
  Type={workshop},
  Year={2012},
  PdfUrl={http://hcitang.org/papers/2012-chi2012workshop-mathsketch.pdf}
}

@inproceedings{grevet2012dinnerprototype,
  Abstract={We aim to explore the inherent social qualities around food consumption
    and the potential role of social systems in the kitchen. We present a prototype
    called FoodApp that allows a group of friends to share each other's dinnertime
    activities. This system is informed by prior work in domestic computing, social
    computing and technology probes design. The main features of the system are
    to support lightweight social cues about cooking and eating activity, as well
    as support for activity coincidences. Future studies of this system will explore
    whether social connectedness in the kitchen can encourage positive behaviors
    around food.},
  Author={Grevet, Catherine and Tang, Anthony and Mynatt, Elizabeth},
  Booktitle={Food and Interaction Design - Workshop at CHI 2012},
  Date-Added={2014-01-18 23:25:40 +0000},
  Date-Modified={2014-01-18 23:28:23 +0000},
  Editor={Rob Comber and Eva Ganglbauer and Jaz Hee-jeong Choi and Jettie Hoonhout
    and Yvonne Rogers and Kenton O'Hara and Julie Maitland},
  Keywords={Social computing, HCI, Food, Awareness},
  Pdfurl={http://hcitang.org/papers/2012-chi2012workshop-dinner-prototype.pdf},
  Title={Description of a Prototype for a Social Awareness System Used During Dinner},
  Type={workshop},
  Year={2012}
}

@inproceedings{polleti2012ecobalance,
  Abstract={Engaging people to regularly reflect on their own behavior is a crucial
    step towards changing it for the better. In this paper we present ECO|Balance,
    a set of interactive design metaphors for mobile devices that aim towards enticing
    continued engagement through using visual appeal and avoiding factors that
    chastise. As a bridge between data visualization and information art the idea
    is to keep people interested in repeatedly working with and analyzing their
    data. We chose the scenario of personal mobility and reducing one's carbon
    footprint and created a series of four animated designs: Pie Flow, Jelly Fish,
    Footprints and Organic Flowers that explore different approaches to representation
    and interaction. We discuss our main goals of long-term enticement through
    visual appeal and subtlety. },
  Author={Polleti, Julia and Baur, Dominikus and Tang, Anthony and Carpendale,
    Sheelagh},
  Booktitle={Personal Informatics in Practice: Improving Quality of Life Through
    Data - Workshop at CHI 2012},
  Date-Added={2014-01-18 23:23:54 +0000},
  Date-Modified={2014-01-18 23:25:27 +0000},
  Editor={Ian Li and Yevgeniy Medynskiy and Jon Froehlich and Jakob Eg Larsen},
  Keywords={Persuasive computing; mobile; personal informatics},
  Pdfurl={http://hcitang.org/papers/2012-chi2012workshop-ecobalance.pdf},
  Title={ECO|Balance - Exploring Design Issues for Mobile Persuasion},
  Type={workshop},
  Year={2012}
}

@inproceedings{aseniero2012deeppersonalization,
  Abstract={Personal informatics (PI) tools that support reflection are ``personalized''
    insofar as the data consists of an individual's data. Typically, this data
    is presented in visualizations that are generic and non-individuated. In this
    paper, we argue for deep personalization, where the visualizations are constructed
    by individuals. Such functionality gives individuals the power to build visualizations
    that are personally meaningful, allowing them to meet and address personal
    needs. We illustrate the power of this approach by considering a case study
    of the design of a multi-faceted reflection tool. Reflecting on the deep personalization
    of the design process, we propose an approach that will allow individuals to
    personalize their own visualizations.},
  Author={Aseniero, Bon Adriel and Carpendale, Sheelagh and Tang, Anthony},
  Booktitle={Personal Informatics in Practice: Improving Quality of Life Through
    Data - Workshop at CHI 2012},
  Date-Added={2014-01-18 23:19:27 +0000},
  Date-Modified={2014-01-18 23:23:16 +0000},
  Editor={Ian Li and Yevgeniy Medynskiy and Jon Froehlich and Jakob Eg Larsen},
  Keywords={Deep personalization, Self-awareness, Aesthetic Design, Information
    Visualization, Feedback techniques},
  Pdfurl={http://hcitang.org/papers/2012-chi2012workshop-deep-personalization.pdf},
  Title={Deep Personalization in Tools for Reflection},
  Type={workshop},
  Year={2012}
}

@inproceedings{macleod2013patientdata,
  Author={MacLeod, Haley and Tang, Anthony},
  Booktitle={Patient-Clinician Communication - Workshop at CHI 2013},
  Date-Added={2014-01-18 23:14:10 +0000},
  Date-Modified={2014-01-18 23:19:12 +0000},
  Editor={Rupa Patel and Lauren Wilcox and Anthony Back and Mary Czerwinski and
    Eric Horvitz and Paul Gorman and Wanda Pratt},
  Pdfurl={http://hcitang.org/papers/2013-chi2013workshop-patient-data.pdf},
  Title={Shared Displays for Facilitating Discussions on Patient Data},
  Type={workshop},
  Year={2013}
}

@inproceedings{ledo2013onespaceworkshop,
  Abstract={Video conferencing commonly employs a video portal met- aphor to connect
    individuals from remote spaces. In this work, we explore an alternate metaphor,
    a shared depth- mirror, where video images of two spaces are fused into a single
    shared, depth-corrected video space. We realize this metaphor in OneSpace,
    where the space respects virtual spatial relationships between people and objects
    as if all parties were looking at a mirror together. We report prelim- inary
    observations of OneSpace's use, noting that it encour- ages cross-site, full-body
    interactions, and that participants employed the depth cues in their interactions.
    Based on these observations, we argue that the depth mirror offers new opportunities
    for shared video interaction in the form of a shared stage.},
  Author={Ledo, David and Aseniero, Bon Adriel and Boring, Sebastian and Greenberg,
    Saul and Tang, Anthony},
  Booktitle={Future of Personal Video Communications: Beyond Talking Heads - Workshop
    at CHI 2013},
  Date-Added={2014-01-18 23:09:42 +0000},
  Date-Modified={2014-01-18 23:13:58 +0000},
  Editor={Erick Oduor and Carman Neustaedter and Gina Venolia and Tejinder Judge},
  Keywords={Video communication; media spaces},
  Pdfurl={http://hcitang.org/papers/2013-chi2013workshop-onespace.pdf},
  Title={OneSpace: Bringing Depth to Remote Interactions},
  Type={workshop},
  Year={2013}
}

@inproceedings{macleod2012personalinformatics,
  Abstract={Personal informatics tools allow individuals to collect and reflect
    on data related to their personal lives. While consumer tools have mainly focused
    on everyday aspects of life, such as physical activity or personal finance,
    they may also provide value to individuals suffering from chronic health conditions.
    These individuals may have unique needs not yet addressed through the current
    design of personal informatics tools. We address this problem through an interview
    study with 15 individuals focused on those with chronic health conditions,
    in which we explored how data collection supported the management of their
    illnesses. We found that data collection gives these individuals a means to
    understand their conditions, as well as a mechanism to manage them.},
  Author={MacLeod, Haley and Tang, Anthony},
  Booktitle={WISH 2012: Workshop on Interactive Systems in Healthcare},
  Date-Added={2014-01-18 23:06:03 +0000},
  Date-Modified={2014-01-18 23:08:55 +0000},
  Pdfurl={http://hcitang.org/papers/2012-wish2012poster-personal-informatics.pdf},
  Title={Understanding Personal Informatics Needs of Individuals with Chronic Health
    Conditions},
  Type={poster},
  Year={2012}
}

@inproceedings{yarosh2013sharetablevideo,
  Author={Yarosh, Svetlana and Tang, Anthony and Mokashi, Sanika and Abowd, Gregory},
  Booktitle={CSCW 2013 Video Showcase Program},
  Date-Added={2014-01-18 21:02:23 +0000},
  Date-Modified={2014-01-18 21:04:54 +0000},
  Notes={People's choice award},
  Title={"Almost Touching": Parent-Child Remote Communication Using the ShareTable
    System - The Video},
  Type={video},
  Videourl={https://www.youtube.com/watch?v=n8k5mYbCXhs},
  Year={2013}
}

@inproceedings{procyk2014sharedgeocachingvideo,
  Abstract={Shared geocaching is an outdoor activity where pairs of individuals
    geocache together but in different locations. Video streaming allows two players
    to see each remote person's view and converse during the activity. This allows
    players to help each other out while searching for geocaches. We envision that
    shared geocaching will provide a way for family or friends to share experiences
    together over distance where they are both participating in the same activity
    at the same time, only in different locations.},
  Author={Procyk, Jason and Neustaedter, Carman and Pang, Carolyn and Tang, Anthony
    and Judge, Tejinder K.},
  Booktitle={CSCW 2014 Video Program},
  Date-Added={2014-01-18 20:32:35 +0000},
  Date-Modified={2014-06-06 17:08:39 +0000},
  Doi={http://dx.doi.org/10.1145/2556420.2557635},
  Notes={video + 4 page abstract},
  Pdfurl={http://hcitang.org/papers/2014-cscw2014videos-shared-geocaching.pdf},
  Publisher={ACM},
  Title={Shared Geocaching Over Distance with Mobile Video Streaming},
  Type={video},
  Videourl={http://hcitang.org/papers/2014-cscw2014videos-shared-geocaching.mov},
  Year={2014},
  Bdsk-Url-1={http://dx.doi.org/10.1145/2556420.2557635}
}

@inproceedings{reilly2010twinspace,
  Author={Reilly, Derek and Tang, Anthony and Wu, Andy and Echenique, Andy and
    Chamoli, Shashank and Massey, Jonathan and Edwards, Warren Keith},
  Booktitle={UIST 2010 Demos: Demonstration Program of ACM Symposium on User Interface
    Technology (UIST) 2010},
  Date-Added={2014-01-18 20:26:14 +0000},
  Date-Modified={2014-01-18 20:28:08 +0000},
  Title={Or de l'Acadie: a Twinspace Demo},
  Type={demo},
  Year={2010}
}

@inproceedings{procyk2014sharedgeocaching,
  Acceptance={22.8{\%} - 471/2064},
  Author={Procyk, Jason and Neustaedter, Carman and Pang, Carolyn and Tang, Anthony
    and Judge, Tejinder K.},
  Booktitle={CHI '14 Proceedings of the SIGCHI Conference on Human Factors in Computing
    Systems},
  Date-Added={2014-01-18 20:24:50 +0000},
  Date-Modified={2014-06-06 17:06:58 +0000},
  Doi={http://dx.doi.org/10.1145/2556288.2557198},
  Pages={2163-2172},
  Pdfurl={http://hcitang.org/papers/2014-chi2014-video-streaming.pdf},
  Publisher={ACM},
  Title={Exploring Video Streaming in Public Settings: Shared Geocaching Over Distance
    Using Mobile Video Chat},
  Type={conference},
  Year={2014},
  Bdsk-Url-1={http://dx.doi.org/10.1145/2556288.2557198}
}

@inproceedings{hunter2014waazaam,
  Abstract={We present the design, implementation and evaluation of WaaZam, a video
    mediated communication system designed to support creative play in personalized
    environments. Users can interact together in sets composed of digital assets
    layered in 3D space. The goal of the project is to support creative play and
    increase social engagement during video sessions of geographically separated
    families. We focus particularly on understanding the value of customization
    for families with children ages 6-12. We present interviews with creativity
    experts, a pilot study and a formal evaluation of families playing together
    in four conditions: separate windows, merged windows, digital play sets, and
    personalized digital environments. We found that playing in the same video
    space enables new activities and increases social engagement for families.
    Personalization allows families to customize environments for their needs and
    supports more creative play activities that embody the imagination of the child.},
  Acceptance={22.8{\%} - 471/2064},
  Author={Hunter, Seth and Maes, Pattie and Tang, Anthony and Inkpen, Kori},
  Booktitle={CHI '14 Proceedings of the SIGCHI Conference on Human Factors in Computing
    Systems},
  Date-Added={2014-01-18 20:23:27 +0000},
  Date-Modified={2014-06-06 17:07:48 +0000},
  Doi={http://dx.doi.org/10.1145/2556288.2557382},
  Keywords={Video mediated communication; customized video environments; composited
    video; family play; remote play; shared experiences at a distance; play at
    a distance},
  Notes={Honourable Mention - Top 5{\%} of all submissions},
  Pages={1197-1206},
  Pdfurl={http://hcitang.org/papers/2014-chi2014-waazam.pdf},
  Publisher={ACM},
  Title={WaaZaam! Supporting Creative Play at a Distance in Customized Video Environments},
  Type={conference},
  Year={2014},
  Bdsk-Url-1={http://dx.doi.org/10.1145/2556288.2557382}
}

@inproceedings{cohen2014onespace,
  Abstract={Children engage in free play for emotional, physical and social development;
    researchers have explored supporting free play between physically remote playmates
    using videoconferencing tools. We show that the configuration of the video
    conferencing setup affects play. Specifically, we show that a shared visual
    scene configuration promotes fundamentally active forms of engaged, co-operative
    play.},
  Acceptance={22.8{\%} - 471/2064},
  Author={Cohen, Maayan and Dillman, Kody and MacLeod, Haley and Hunter, Seth and
    Tang, Anthony},
  Booktitle={CHI '14 Proceedings of the SIGCHI Conference on Human Factors in Computing
    Systems},
  Date-Added={2014-01-18 20:20:57 +0000},
  Date-Modified={2014-06-06 17:07:53 +0000},
  Doi={http://dx.doi.org/10.1145/2556288.2557117},
  Notes={Honourable Mention - Top 5{\%} of all submissions},
  Pages={2177-2180},
  Pdfurl={http://hcitang.org/papers/2014-chi2014-freeplay.pdf},
  Publisher={ACM},
  Title={OneSpace: Shared Visual Scenes for Active Freeplay},
  Type={conference},
  Videourl={http://hcitang.org/papers/2014-chi2014-freeplay-in-onespace.mov},
  Year={2014},
  Bdsk-Url-1={http://dx.doi.org/10.1145/2556288.2557117}
}

@inproceedings{macleod2013towards,
  Abstract={Many people with chronic illness suffer from debilitating symptoms
    that inhibit normal day-to-day function. It is unclear how to design tools
    to support this -- many see self-tracking tools as a burden to use. We report
    here on an interview study with 12 individuals with chronic illnesses who collect
    data about their conditions. We reflect on ways to support the design of tools
    that will be more easily adopted by engaging curiosity, self-discovery and
    exploration rather than focusing on behavior change. },
  Author={MacLeod, Haley and Tang, Anthony and Carpendale, Sheelagh},
  Booktitle={GRAND 2013: RNote Proceedings of the GRAND NCE 2013 Meeting},
  Date-Added={2014-01-17 05:52:13 +0000},
  Date-Modified={2014-01-17 05:53:11 +0000},
  Pdfurl={http://hcitang.org/papers/2013-grand2013-towards-personal-informatics-tools.pdf},
  Title={Towards Personal Informatics Tools for Chronic Illness Management},
  Year={2013}
}

@inproceedings{tang2013annotation,
  Abstract={Just as we annotate digital documents with digital annotations for
    collaborative work, we frequently annotate physical objects using physical
    annotations (e.g. by using Post-It notes). In the physical world, we are limited
    by the size of the physical Post-It note, and further, too many Post-It notes
    clutter the physical space. In this work, we explore the use of handheld projectors
    combined with a tablet to create digital annotations for physical objects,
    and to visualize these annotations around such physical objects. Our design
    allows people to use a flashlight metaphor for visualizing digital ``post-it''
    notes, which can be created in-place by pointing the projector at an object,
    and then adding the annotation using the tablet. We realized this design in
    a prototype to informally assess the effectiveness of the metaphors we used,
    and to gather suggestions for future work in this area},
  Author={Tang, Richard and Tang, Anthony},
  Booktitle={GRAND 2013: RNote Proceedings of the GRAND NCE 2013 Meeting},
  Date-Added={2014-01-17 05:50:19 +0000},
  Date-Modified={2014-01-17 05:51:35 +0000},
  Pdfurl={http://hcitang.org/papers/2013-grand2013-in-place-annotation.pdf},
  Title={In-Place Annotation of Physical Objects with Pico-Projectors},
  Year={2013}
}

@inproceedings{weigel2013focus,
  Abstract={Focus plus context displays combine high-resolution detail and lower-resolution
    overview using displays of different pixel densities. Historically, they employed
    two fixed-size displays of different resolutions, one embedded within the other.
    In this paper, we explore focus plus context displays using one or more mobile
    projectors in combination with a stationary display. The portability of mobile
    projectors as applied to focus plus context displays contributes in three ways.
    First, the projector's projection on the stationary display can transition
    dynamically from being the focus of one's interest (i.e. providing a high resolution
    view when close to the display) to providing context around it (i.e. providing
    a low resolution view beyond the display's borders when further away from it).
    Second, users can dynamically reposition and resize a focal area that matches
    their interest rather than repositioning all content into a fixed high-resolution
    area. Third, multiple users can manipulate multiple foci or context areas without
    interfering with one other. A proof-of-concept implementation illustrates these
    contributions. },
  Author={Weigel, Martin and Boring, Sebastian and Marquardt, Nicolai and Steimle,
    Juergen and Greenberg, Saul and Tang, Anthony},
  Booktitle={GRAND 2013: RNote Proceedings of the GRAND NCE 2013 Meeting},
  Date-Added={2014-01-17 05:47:05 +0000},
  Date-Modified={2014-01-17 05:49:59 +0000},
  Keywords={Focus plus context, portable projectors, multiple users, multiple displays},
  Notes={Honourable mention},
  Pdfurl={http://hcitang.org/papers/2013-grand2013-focus-to-context-and-back.pdf},
  Title={From Focus to Context and Back: Combining Mobile Projectors and Stationary
    Displays},
  Year={2013}
}

@techreport{dillman2015bodyasworkspace,
  Abstract={Many common injuries can be treated effectively with physiotherapy, but accessing this treatment is difficult for those in rural locations. We seek to design video-based systems to support remote physiotherapy, so patients can access and engage with therapy and a professional from their homes. We conducted design sessions with practicing physiotherapists to iteratively design and build technology sketches to understand communication challenges and practices for remote therapy. Our analysis of these sessions reveals new challenges in designing video media space tools for telerehabilitation. Chief among these lessons: supporting body-based communication between therapist and patient is challenging because the object of conversation is the patient’s body rather than an external object that can be manipulated.},
  Author={Dillman, Kody and Tang, Anthony},
  Institution={University of Calgary},
  Keywords={Physiotherapy, remote collaboration, telerehabilitation},
  Month={April},
  Number={2015-1071-04},
  Pdfurl={http://dspace.ucalgary.ca/bitstream/1880/50412/1/2015-1071-04.pdf},
  Publisher={Department of Computer Science, University of Calgary},
  Title={Body as a Workspace: Design for Remote Physiotherapy},
  Type={techreport},
  Year={2015},
}  

@techreport{dillman2013remotephysiotherapy,
  Abstract={Many common injuries can be treated effectively withphysiotherapy,
    but getting access to this treatment isdifficult for those living in remote
    or rural locations. Tohelp formulate design requirements for next-generationtools
    for supporting remote physiotherapy (i.e.telerehabilitation), we conducted
    design sessions with fivepracticing physiotherapists. We developed three technologyprobes
    as prompts for these discussions, helping us to gainan understanding of physiotherapists'
    activities andcommunication practices. Our analysis shows thattelerehabilitation
    tools should be specifically designed toaddress communication and work in relation
    to clients'physical bodies, and that visual communication can beenhanced through
    augmentation to videoconferencing toolsand accessible hardware to account for
    a lack of tactilecommunication.},
  Author={Dillman, Kody and Tang, Anthony},
  Citation_Abstract_Html_Url={http://dspace.ucalgary.ca/jspui/handle/1880/49845},
  Citation_Authors={Tang, Anthony; Dillman, Kody},
  Citation_Date={2013-09-25},
  Citation_Keywords={Remote Physiotherapy, injuries; Technical Report},
  Citation_Language={eng},
  Citation_Pdf_Url={http://dspace.ucalgary.ca/jspui/bitstream/1880/49845/1/2013-1048-15.pdf},
  Citation_Title={Towards Next-Generation Remote Physiotherapy with Videoconferencing
    Tools},
  Date-Added={2014-01-16 05:18:04 +0000},
  Date-Modified={2014-01-16 05:27:39 +0000},
  Dc.Identifier={2013-1048-15},
  Dc.Language={eng},
  Dc.Type={Technical Report},
  Dcterms.Available={2013-09-25T19:34:33Z},
  Dcterms.Dateaccepted={2013-09-25T19:34:33Z},
  Dcterms.Issued={2013-09-25},
  Generator={DSpace},
  Institution={University of Calgary},
  Keywords={Videoconferencing Tools, Telerehabilitation},
  Month={September},
  Number={2013-1048-15},
  Pdfurl={http://dspace.ucalgary.ca/jspui/bitstream/1880/49845/1/2013-1048-15.pdf},
  Publisher={Department of Computer Science, University of Calgary},
  Title={Towards Next-Generation Remote Physiotherapy with Videoconferencing Tools},
  Type={techreport},
  Url={http://hdl.handle.net/1880/49845},
  Year={2013},
  Bdsk-Url-1={http://hdl.handle.net/1880/49845}
}

@inproceedings{boring2012fat,
  Abstract={Modern mobile devices allow a rich set of multi-finger interactions
    that combine modes into a single fluid act, for example, one finger for panning
    blending into a two-finger pinch gesture for zooming. Such gestures require
    the use of both hands: one holding the device while the other is interacting.
    While on the go, however, only one hand may be available to both hold the device
    and interact with it. This mostly limits interaction to a single-touch (i.e.,
    the thumb), forcing users to switch between input modes explicitly. In this
    paper, we contribute the Fat Thumb interaction technique, which uses the thumb's
    contact size as a form of simulated pressure. This adds a degree of freedom,
    which can be used, for example, to integrate panning and zooming into a single
    interaction. Contact size determines the mode (i.e., panning with a small size,
    zooming with a large one), while thumb movement performs the selected mode.
    We discuss nuances of the Fat Thumb based on the thumb's limited operational
    range and motor skills when that hand holds the device. We compared Fat Thumb
    to three alternative techniques, where people had to precisely pan and zoom
    to a predefined region on a map and found that the Fat Thumb technique compared
    well to existing techniques.},
  Acceptance={25{\%} - 54/212},
  Acmid={2371582},
  Address={New York, NY, USA},
  Author={Boring, Sebastian and Ledo, David and Chen, Xiang 'Anthony' and Marquardt,
    Nicolai and Tang, Anthony and Greenberg, Saul},
  Booktitle={Proceedings of the 14th International Conference on Human-computer
    Interaction with Mobile Devices and Services},
  Date-Added={2014-01-11 20:51:34 +0000},
  Date-Modified={2014-01-11 20:54:23 +0000},
  Doi={http://doi.acm.org/10.1145/2371574.2371582},
  Isbn={978-1-4503-1105-2},
  Keywords={mobile device, single-handed interaction, touch-screen},
  Location={San Francisco, California, USA},
  Numpages={10},
  Pages={39--48},
  Publisher={ACM},
  Series={MobileHCI '12},
  Title={The Fat Thumb: Using the Thumb's Contact Size for Single-handed Mobile
    Interaction},
  Type={conference},
  Videourl={http://hcitang.org/papers/2012-mobilehci2012-fatthumb.mp4},
  Year={2012},
  PdfUrl={http://hcitang.org/papers/2012-mobilehci2012-fatthumb.pdf},
  Bdsk-Url-1={http://doi.acm.org/10.1145/2371574.2371582},
  Bdsk-Url-2={http://dx.doi.org/10.1145/2371574.2371582}
}

@inproceedings{boring2012fatdemo,
  Abstract={Modern mobile devices allow a rich set of multi-finger interactions
    that combine modes into a single fluid act, for example, one finger for panning
    blending into a two-finger pinch gesture for zooming. Such gestures require
    the use of both hands: one holding the device while the other is interacting.
    While on the go, however, only one hand may be available to both hold the device
    and interact with it. This mostly limits interaction to a single-touch (i.e.,
    the thumb), forcing users to switch between input modes explicitly. In this
    paper, we contribute the Fat Thumb interaction technique, which uses the thumb's
    contact size as a form of simulated pressure. This adds a degree of freedom,
    which can be used, for example, to integrate panning and zooming into a single
    interaction. Contact size determines the mode (i.e., panning with a small size,
    zooming with a large one), while thumb movement performs the selected mode.
    We discuss nuances of the Fat Thumb based on the thumb's limited operational
    range and motor skills when that hand holds the device. We compared Fat Thumb
    to three alternative techniques, where people had to precisely pan and zoom
    to a predefined region on a map and found that the Fat Thumb technique compared
    well to existing techniques.},
  Address={New York, NY, USA},
  Author={Boring, Sebastian and Ledo, David and Chen, Xiang 'Anthony' and Marquardt,
    Nicolai and Tang, Anthony and Greenberg, Saul},
  Booktitle={Proceedings of the 14th International Conference on Human-computer
    Interaction with Mobile Devices and Services Companion},
  Date-Added={2014-01-11 20:50:16 +0000},
  Date-Modified={2014-01-11 20:53:42 +0000},
  Doi={http://doi.acm.org/10.1145/2371664.2371711},
  Isbn={978-1-4503-1443-5},
  Keywords={mobile device, single-handed interaction, touch-screen},
  Location={San Francisco, California, USA},
  Numpages={2},
  Pages={207--208},
  Publisher={ACM},
  Series={MobileHCI '12},
  Title={The Fat Thumb: Using the Thumb's Contact Size for Single-handed Mobile
    Interaction},
  Type={demo},
  Videourl={http://hcitang.org/papers/2012-mobilehci2012-fatthumb.mp4},
  Year={2012},
  Bdsk-Url-1={http://doi.acm.org/10.1145/2371664.2371711},
  Bdsk-Url-2={http://dx.doi.org/10.1145/2371664.2371711}
}

@article{neustaedter2013creating,
  Abstract={Location-based games seek to move computer gaming out from behind the
    PC and into the ``real world'' of cities, streets, parks, and other locations.
    This real-world physicality makes the experience fun for game players, yet
    it brings the unique challenge of creating and orchestrating such a game. That
    is, location-based games are often difficult to create, grow, and maintain
    over long periods of time. Our research investigates how location-based games
    can be designed to overcome this challenge of scalability. We studied the well-established
    location-based game of Geocaching through active participation and an online
    survey to better understand how it has succeeded in maintaining user involvement
    and growth over the last decade. Findings show that Geocaching benefits by
    having players directly create game content, including both lightweight and
    elaborate creations. Geocaching has also made it simple for players to perform
    game orchestration by monitoring game content, other players, and even non-players.
    We then characterize location-based games according to various attributes and
    suggest how the lessons learned from Geocaching could be applied more generally
    to the design of other location-based games and in which cases they should
    not be applied.},
  Address={London, UK, UK},
  Author={Neustaedter, Carman and Tang, Anthony and Judge, Tejinder K.},
  Date-Modified={2014-01-11 07:00:43 +0000},
  Doi={http://dx.doi.org/10.1007/s00779-011-0497-7},
  Issn={1617-4909},
  Journal={Personal Ubiquitous Comput.},
  Keywords={Geocaching, Pervasive games, Location-based games, Community, Global
    positioning system (GPS)},
  Number={2},
  Pages={335--349},
  Pdfurl={http://hcitang.org/papers/2011-puc-scalable-location-based-games.pdf},
  Publisher={Springer-Verlag},
  Title={Creating scalable location-based games: lessons from Geocaching},
  Type={journal},
  Volume={17},
  Year={2013},
  Bdsk-Url-1={http://dx.doi.org/10.1007/s00779-011-0497-7}
}

@article{isenberg2013data,
  Abstract={Interactive tabletops and surfaces (ITSs) provide rich opportunities
    for data visualization and analysis and consequently are used increasingly
    in such settings. A research agenda of some of the most pressing challenges
    related to visualization on ITSs emerged from discussions with researchers
    and practitioners in human-computer interaction, computer-supported collaborative
    work, and a variety of visualization fields at the 2011 Workshop on Data Exploration
    for Interactive Surfaces (Dexis 2011) },
  Author={Isenberg, Petra and Isenberg, Tobias and Hesselmann, Tobias and Lee,
    Bongshin and Von Zadow, Ulrich and Tang, Anthony},
  Date-Modified={2014-01-11 05:50:35 +0000},
  Doi={http://doi.ieeecomputersociety.org/10.1109/MCG.2013.24},
  Journal={Computer Graphics and Applications, IEEE},
  Keywords={Data visualization,Interactive systems,Computer graphics,User interfaces,multitouch,Data
    visualization,Interactive systems,Computer graphics,User interfaces,computer
    graphics,visualization,interactive surfaces,display technology},
  Number={2},
  Pages={16--24},
  Pdfurl={http://hcitang.org/papers/2013-cga-data-visualization-on-interactive-surfaces.pdf},
  Publisher={IEEE},
  Title={Data visualization on interactive surfaces: A research agenda},
  Type={journal},
  Volume={33},
  Year={2013},
  Bdsk-Url-1={http://doi.ieeecomputersociety.org/10.1109/MCG.2013.24}
}

@article{tang2005understanding,
  Abstract={Mixed Presence Groupware (MPG) supports both co-located and distributed
    participants working over a shared visual workspace. It does so by connecting
    multiple single-display groupware workspaces together through a shared data
    structure. Our implementation and observations of MPG systems exposes two problems:
    the first is display disparity, where connecting heterogeneous displays introduces
    issues in how people are seated around the workspace and how workspace artifacts
    are oriented; the second problem is presence disparity, where the perceived
    presence of collaborators is markedly different depending on whether they are
    co-located or remote. Presence disparity is likely caused by inadequate consequential
    communication between remote participants, which in turn disrupts group collaborative
    and communication dynamics. To mitigate display and presence disparity problems,
    we determine virtual seating positions and replace conventional telepointers
    with digital arm shadows that extend from a person's side of the table to their
    pointer location.},
  Author={Tang, Anthony and Boyle, Michael and Greenberg, Saul},
  Date-Modified={2014-01-17 05:14:49 +0000},
  Journal={Journal of research and practice in information technology},
  Notes={Invited article},
  Number={2},
  Pages={193--210},
  Pdfurl={http://hcitang.org/papers/2005-jrpit-tang-display-and-presence-disparity.pdf},
  Publisher={Sydney, Australia: Australian Computer Society, c2000-},
  Title={Understanding and mitigating display and presence disparity in mixed presence
    groupware},
  Type={journal},
  Volume={37},
  Year={2005}
}

@article{jeffrey2006chasing,
  Abstract={We report on our experiences with building and deploying a collaborative
    location-based mobile game. The Fugitive is a multiplayer game that is played
    using mobile TabletPCs in a natural campus environment. The objective is to
    track and capture a hidden object called the Fugitive on a digital campus map
    using annotations for communication among one's teammates. We discuss the design,
    development, and network infrastructure as well as focus group and observational
    findings from our field study. Our findings suggest that the effect of location-awareness
    on collaboration and game play strategies is an intriguing area for study,
    and we share our insights from this project with the Canadian Game Studies
    community. },
  Author={Jeffrey, Phillip and Blackstock, Mike and Finke, Matthias and Tang, Anthony
    and Lea, Rodger and Deutscher, Meghan and Miyaoku, Kento},
  Date-Modified={2014-01-17 05:12:24 +0000},
  Journal={Loading.. Journal},
  Number={1},
  Pdfurl={http://hcitang.org/papers/2006-cgsa2006-chasing-the-fugitive-full.pdf},
  Title={Chasing the Fugitive on Campus: Designing a Location-based Game for Collaborative
    Play},
  Type={journal},
  Volume={1},
  Year={2006}
}

@article{miyaoku2007c,
  Author={Miyaoku, Kento and Tang, Anthony and Fels, Sidney},
  Journal={Information Processing Society of Japan Journal},
  Number={3},
  Pages={1361--1371},
  Title={C-Band: A Ring Tag System Using A Color Pattern Code},
  Type={journal},
  Volume={48},
  Year={2007}
}

@inproceedings{seyed2013skyhunter,
  Abstract={The process of oil and gas exploration and its result, the decision
    to drill for oil in a specific location, relies on a number of distinct but
    related domains. These domains require effective collaboration to come to a
    decision that is both cost effective and maintains the integrity of the environment.
    As we show in this paper, many of the existing technologies and practices that
    support the oil and gas exploration process overlook fundamental user issues
    such as collaboration, interaction and visualization. The work presented in
    this paper is based upon a design process that involved expert users from an
    oil and gas exploration firm in Calgary, Alberta, Canada. We briefly present
    knowledge of the domain and how it informed the design of SkyHunter, a prototype
    multi-surface environment to support oil and gas exploration. This paper highlights
    our current prototype and we conclude with a reflection on multi-surface interactions
    and environments in this domain.},
  Acceptance={29{\%} - 35/121},
  Address={New York, NY, USA},
  Author={Seyed, Teddy and Costa Sousa, Mario and Maurer, Frank and Tang, Anthony},
  Booktitle={ITS '13: Proceedings of the 2013 ACM international conference on Interactive
    tabletops and surfaces},
  Date-Modified={2014-01-11 04:35:50 +0000},
  Doi={http://doi.acm.org/10.1145/2512349.2512798},
  Isbn={978-1-4503-2271-3},
  Keywords={Oil and gas; multi-surface environments; tabletops; gestures; cross-device
    interaction; mobile devices},
  Location={St. Andrews, Scotland, United Kingdom},
  Pages={15--22},
  Pdfurl={http://hcitang.org/papers/2013-its2013-skyhunter.pdf},
  Publisher={ACM},
  Title={SkyHunter: a multi-surface environment for supporting oil and gas exploration},
  Type={conference},
  Year={2013},
  Bdsk-Url-1={http://doi.acm.org/10.1145/2512349.2512798}
}

@inproceedings{weigel2013projectorkit,
  Abstract={Researchers have developed interaction concepts based on mobile projectors.
    Yet pursuing work in this area - particularly in building projector-based interactions
    techniques within an application - is cumbersome and time-consuming. To mitigate
    this problem, we contribute ProjectorKit, a flexible open-source toolkit that
    eases rapid prototyping mobile projector interaction techniques.},
  Acceptance={22{\%} - 53/238},
  Address={New York, NY, USA},
  Author={Weigel, Martin and Boring, Sebastian and Steimle, J\"{u}rgen and Marquardt,
    Nicolai and Greenberg, Saul and Tang, Anthony},
  Booktitle={MobileHCI '13: Proceedings of the 15th international conference on
    Human-computer interaction with mobile devices and services},
  Date-Modified={2014-01-11 05:37:56 +0000},
  Doi={http://doi.acm.org/10.1145/2493190.2493242},
  Isbn={978-1-4503-2273-7},
  Keywords={mobile projectors, toolkit, rapid prototyping},
  Location={Munich, Germany},
  Pages={247--250},
  Pdfurl={http://hcitang.org/papers/2013-mobilehci2013-projectorkit.pdf},
  Publisher={ACM},
  Title={ProjectorKit: easing rapid prototyping of interactive applications for
    mobile projectors},
  Type={conference},
  Url={http://grouplab.cpsc.ucalgary.ca/cookbook/index.php/Toolkits/ProjectorKit},
  Year={2013},
  Bdsk-Url-1={http://grouplab.cpsc.ucalgary.ca/cookbook/index.php/Toolkits/ProjectorKit},
  Bdsk-Url-2={http://doi.acm.org/10.1145/2493190.2493242}
}

@inproceedings{macleod2013personal,
  Abstract={Many people with chronic illness suffer from debilitating symptoms
    or episodes that inhibit normal day-to-day function. Pervasive tools offer
    the possibility to help manage these conditions, particularly by helping people
    understand their conditions. But, it is unclear how to design these tools,
    as prior designs have focused on effortful tracking and many see those tools
    as a burden to use. We report here on an interview study with 12 individuals
    with chronic illnesses who collect personal data. We learn that these people
    are motivated through self- discovery and curiosity. We explore how these concepts
    may support the design of tools that engage curiosity and encourage self-discovery,
    rather than emphasize the behaviour change aspect of chronic illness management.},
  Acceptance={38{\%} - 16/42},
  Address={Toronto, Ont., Canada, Canada},
  Author={MacLeod, Haley and Tang, Anthony and Carpendale, Sheelagh},
  Booktitle={GI '13: Proceedings of the 2013 Graphics Interface Conference},
  Date-Modified={2014-01-11 05:46:58 +0000},
  Isbn={978-1-4822-1680-6},
  Keywords={Personal informatics, Healthcare, Chronic disease management, Qualitative
    studies.},
  Location={Regina, Sascatchewan, Canada},
  Pages={149--156},
  Pdfurl={http://hcitang.org/papers/2013-gi2013-personal-informatics.pdf},
  Publisher={Canadian Information Processing Society},
  Title={Personal informatics in chronic illness management},
  Type={conference},
  Year={2013}
}

@inproceedings{yarosh2013almost,
  Abstract={We deployed the ShareTable - a system that provides easy-to-initiate
    videochat and a shared tabletop task space - in four divorced households. Throughout
    the month of its use, the families employed the ShareTable to participate in
    shared activities, share emotional moments, and communicate closeness through
    metaphorical touch. The ShareTable provided a number of advantages over the
    phone and was easier to use than standard videoconferencing. However, it did
    also introduce concerns over privacy and new sources of conflict about appropriate
    calling practices. We relate our findings to the larger research landscape
    and present implications for future work.},
  Acceptance={35.5{\%} - 139/390},
  Address={New York, NY, USA},
  Author={Yarosh, Svetlana and Tang, Anthony and Mokashi, Sanika and Abowd, Gregory
    D.},
  Booktitle={CSCW '13: Proceedings of the 2013 conference on Computer supported
    cooperative work},
  Date-Modified={2014-01-11 06:55:49 +0000},
  Doi={http://doi.acm.org/10.1145/2441776.2441798},
  Isbn={978-1-4503-1331-5},
  Keywords={Computer-mediated communication, divorced families, children, tabletop,
    camera-projector system, home},
  Location={San Antonio, Texas, USA},
  Pages={181--192},
  Pdfurl={http://hcitang.org/papers/2013-cscw2013-almost-touching.pdf},
  Publisher={ACM},
  Rating={4},
  Title={"Almost touching": parent-child remote communication using the sharetable
    system},
  Type={conference},
  Videourl={http://hcitang.org/papers/2013-cscw2013-almost-touching.m4v},
  Year={2013},
  Bdsk-Url-1={http://doi.acm.org/10.1145/2441776.2441798}
}

@inproceedings{genest2013kinectarms,
  Abstract={Gestures are a ubiquitous part of human communication over tables,
    but when tables are distributed, gestures become difficult to capture and represent.
    There are several problems: extracting arm images from video, representing
    the height of the gesture, and making the arm embodiment visible and understandable
    at the remote table. Current solutions to these problems are often expensive,
    complex to use, and difficult to set up. We have developed a new toolkit --
    KinectArms -- that quickly and easily captures and displays arm embodiments.
    KinectArms uses a depth camera to segment the video and determine gesture height,
    and provides several visual effects for representing arms, showing gesture
    height, and enhancing visibility. KinectArms lets designers add rich arm embodiments
    to their systems without undue cost or development effort, greatly improving
    the expressiveness and usability of distributed tabletop groupware},
  Acceptance={35.5{\%} - 139/390},
  Address={New York, NY, USA},
  Author={Genest, Aaron M. and Gutwin, Carl and Tang, Anthony and Kalyn, Michael
    and Ivkovic, Zenja},
  Booktitle={CSCW '13: Proceedings of the 2013 conference on Computer supported
    cooperative work},
  Date-Modified={2014-01-11 06:56:05 +0000},
  Doi={http://doi.acm.org/10.1145/2441776.2441796},
  Isbn={978-1-4503-1331-5},
  Keywords={Distributed tabletops, gestures, embodiments, toolkits},
  Location={San Antonio, Texas, USA},
  Pages={157--166},
  Pdfurl={http://hcitang.org/papers/2013-cscw2013-kinectarms.pdf},
  Publisher={ACM},
  Title={KinectArms: a toolkit for capturing and displaying arm embodiments in
    distributed tabletop groupware},
  Type={conference},
  Videourl={http://hcitang.org/papers/2013-cscw2013-kinectarms.m4v},
  Year={2013},
  Bdsk-Url-1={http://doi.acm.org/10.1145/2441776.2441796}
}

@inproceedings{seyed2012eliciting,
  Abstract={Multi-display environments (MDEs) have advanced rapidly in recent years,
    incorporating multi-touch tabletops, tablets, wall displays and even position
    tracking systems. Designers have proposed a variety of interesting gestures
    for use in an MDE, some of which involve a user moving their hands, arms, body
    or even a device itself. These gestures are often used as part of interactions
    to move data between the various components of an MDE, which is a longstanding
    research problem. But designers, not users, have created most of these gestures
    and concerns over implementation issues such as recognition may have influenced
    their design. We performed a user study to elicit these gestures directly from
    users, but found a low level of convergence among the gestures produced. This
    lack of agreement is important and we discuss its possible causes and the implication
    it has for designers. To assist designers, we present the most prevalent gestures
    and some of the underlying conceptual themes behind them. We also provide analysis
    of how certain factors such as distance and device type impact the choice of
    gestures and discuss how to apply them to real-world systems. },
  Acceptance={29{\%} - 30/103},
  Address={New York, NY, USA},
  Author={Seyed, Teddy and Burns, Chris and Costa Sousa, Mario and Maurer, Frank
    and Tang, Anthony},
  Booktitle={ITS '12: Proceedings of the 2012 ACM international conference on Interactive
    tabletops and surfaces},
  Date-Modified={2014-01-11 20:42:55 +0000},
  Doi={http://doi.acm.org/10.1145/2396636.2396643},
  Isbn={978-1-4503-1209-7},
  Keywords={Tabletop; gestures; multi-display environments; multi- surface environments;
    multi-display interaction; cross-device interaction; touch; mobile devices},
  Location={Cambridge, Massachusetts, USA},
  Pages={41--50},
  Pdfurl={http://hcitang.org/papers/2012-its2012-eliciting-usable-gestures.pdf},
  Publisher={ACM},
  Title={Eliciting usable gestures for multi-display environments},
  Type={conference},
  Year={2012},
  Bdsk-Url-1={http://doi.acm.org/10.1145/2396636.2396643}
}

@inproceedings{grevet2012eating,
  Abstract={Eating with others, or commensality, is an enjoyable activity that
    serves many important social functions; however, many individuals eat meals
    alone due to life circumstances, meaning that they miss out on these social
    benefits. We developed and deployed a simple technology probe providing social
    awareness around mealtimes to explore how social systems might help alleviate
    the loneliness of solitary dining. Our findings suggest that these systems
    can convey a sense of connectedness around a meal; further, our analysis revealed
    three themes relevant to systems of this type: that contextually-located peripheral
    awareness engenders connectedness; that such tools can foster a feeling of
    shared social presence, and that they can be a catalyst for other forms of
    communication around the meal. These findings suggest that ``remote commensality''
    is not only possible, but that it may take on forms entirely different to that
    which we are accustomed. },
  Acceptance={25.5{\%} - 24/94},
  Address={New York, NY, USA},
  Author={Grevet, Catherine and Tang, Anthony and Mynatt, Elizabeth},
  Booktitle={GROUP '12: Proceedings of the 17th ACM international conference on
    Supporting group work},
  Date-Modified={2014-01-11 20:45:46 +0000},
  Doi={http://doi.acm.org/10.1145/2389176.2389192},
  Isbn={978-1-4503-1486-2},
  Keywords={HCI, Social computing, Awareness, Contextual information, Design, Food,
    Mealtime},
  Location={Sanibel Island, Florida, USA},
  Pages={103--106},
  Pdfurl={http://hcitang.org/papers/2012-group2012-eating-alone-together.pdf},
  Publisher={ACM},
  Title={Eating alone, together: new forms of commensality},
  Type={conference},
  Year={2012},
  Bdsk-Url-1={http://doi.acm.org/10.1145/2389176.2389192}
}

@inproceedings{chen2012extending,
  Abstract={Modern mobile devices rely on the screen as a primary input modality.
    Yet the small screen real-estate limits interaction possibilities, motivating
    researchers to explore alternate input techniques. Within this arena, our goal
    is to develop Body-Centric Interaction with Mobile Devices: a class of input
    techniques that allow a person to position and orient her mobile device to
    navigate and manipulate digital content anchored in the space on and around
    the body. To achieve this goal, we explore such interaction in a bottom-up
    path of prototypes and implementations. From our experiences, as well as by
    examining related work, we discuss and present three recurring themes that
    characterize how these interactions can be realized. We illustrate how these
    themes can inform the design of Body-Centric Interactions by applying them
    to the design of a novel mobile browser application. Overall, we contribute
    a class of mobile input techniques where interactions are extended beyond the
    small screen, and are instead driven by a person's movement of the device on
    and around the body.},
  Acceptance={25{\%} - 54/212},
  Address={New York, NY, USA},
  Author={Chen, Xiang 'Anthony' and Marquardt, Nicolai and Tang, Anthony and Boring,
    Sebastian and Greenberg, Saul},
  Booktitle={MobileHCI '12: Proceedings of the 14th international conference on
    Human-computer interaction with mobile devices and services},
  Date-Modified={2014-01-11 20:47:56 +0000},
  Doi={http://doi.acm.org/10.1145/2371574.2371599},
  Isbn={978-1-4503-1105-2},
  Keywords={Body-Centric Interaction, mobile device, mobile interaction},
  Location={San Francisco, California, USA},
  Pages={151--160},
  Pdfurl={http://hcitang.org/papers/2012-mobilehci2012-body-centric-interaction.pdf},
  Publisher={ACM},
  Title={Extending a mobile device's interaction space through body-centric interaction},
  Type={conference},
  Videourl={http://vimeo.com/31172179},
  Year={2012},
  Bdsk-Url-1={http://doi.acm.org/10.1145/2371574.2371599}
}

@inproceedings{chen2012spalendar,
  Abstract={Portable paper calendars (i.e., day planners and organizers) have greatly
    influenced the design of group electronic calendars. Both use time units (hours/days/weeks/etc.)
    to organize visuals, with useful information (e.g., event types, locations,
    attendees) usually presented as - perhaps abbreviated or even hidden - text
    fields within those time units. The problem is that, for a group, this visual
    sorting of individual events into time buckets conveys only limited information
    about the social network of people. For example, people's whereabouts cannot
    be read `at a glance' but require examining the text. Our goal is to explore
    an alternate visualization that can reflect and illustrate group members' calendar
    events. Our main idea is to display the group's calendar events as spatiotemporal
    activities occurring over a geographic space animated over time, all presented
    on a highly interactive public display. In particular, our SPALENDAR (SPAtial
    CALENDAR) design animates people's past, present and forthcoming movements
    between event locations as well as their static locations. Detail of people's
    events, their movements and their locations is progressively revealed and controlled
    by the viewer's proximity to the display, their identity, and their gestural
    interactions with it, all of which are tracked by the public display. },
  Address={New York, NY, USA},
  Author={Chen, Xiang 'Anthony' and Boring, Sebastian and Carpendale, Sheelagh
    and Tang, Anthony and Greenberg, Saul},
  Booktitle={AVI '12: Proceedings of the International Working Conference on Advanced
    Visual Interfaces},
  Date-Modified={2014-01-12 17:10:29 +0000},
  Doi={http://doi.acm.org/10.1145/2254556.2254686},
  Isbn={978-1-4503-1287-5},
  Keywords={Calendar, group, visualization, location, situated interaction},
  Location={Capri Island, Italy},
  Pages={689--696},
  Publisher={ACM},
  Title={Spalendar: visualizing a group's calendar events over a geographic space
    on a public display},
  Type={conference},
  Videourl={http://vimeo.com/31823922},
  Year={2012},
  Bdsk-Url-1={http://doi.acm.org/10.1145/2254556.2254686}
}

@inproceedings{tang2012epicplay,
  Abstract={During a live sports event, many sports fans use social media as a
    part of their viewing experience, reporting on their thoughts on the event
    as it unfolds. In this work, we use this information stream to semantically
    annotate live broadcast sports games, using these annotations to select video
    highlights from the game. We demonstrate that this approach can be used to
    select highlights specific for fans of each team, and that these clips reflect
    the emotions of a fan during a game. Further, we describe how these clips differ
    from those seen on nightly sportscasts.},
  Acceptance={23.4{\%} - 369/1577},
  Address={New York, NY, USA},
  Author={Tang, Anthony and Boring, Sebastian},
  Booktitle={CHI '12: Proceedings of the SIGCHI Conference on Human Factors in
    Computing Systems},
  Date-Modified={2014-01-11 06:50:16 +0000},
  Doi={http://doi.acm.org/10.1145/2207676.2208622},
  Isbn={978-1-4503-1015-4},
  Keywords={Crowd-sourcing; Video summarization; Sports; Twitter; Microblogging;
    Broadcast sports; Video annotation.},
  Location={Austin, Texas, USA},
  Pages={1569--1572},
  Pdfurl={http://hcitang.org/papers/2012-chi2012-epicplay.pdf},
  Publisher={ACM},
  Title={\#EpicPlay: crowd-sourcing sports video highlights},
  Type={conference},
  Year={2012},
  Bdsk-Url-1={http://doi.acm.org/10.1145/2207676.2208622}
}

@inproceedings{tang2012verbal,
  Abstract={We explore how expert First Person Shooter (FPS) players coordinate
    actions using a shared voice channel. Our findings emphasize the importance
    of the temporality and spatiality of these tactical verbal communications ("call-outs").
    From here, we outline potential designs to mitigate problems in the production/interpretation
    of call-outs to better support coordination.},
  Acceptance={29.6{\%} - 37/125 for notes},
  Address={New York, NY, USA},
  Author={Tang, Anthony and Massey, Jonathan and Wong, Nelson and Reilly, Derek
    and Edwards, W. Keith},
  Booktitle={CSCW '12: Proceedings of the ACM 2012 conference on Computer Supported
    Cooperative Work},
  Date-Modified={2014-01-11 07:01:08 +0000},
  Doi={http://doi.acm.org/10.1145/2145204.2145292},
  Isbn={978-1-4503-1086-4},
  Keywords={First person shooter, FPS, CVE, coordination, First person shooter,
    FPS, CVE, coordination},
  Location={Seattle, Washington, USA},
  Pages={579--582},
  Pdfurl={http://hcitang.org/papers/2012-cscw2012-fps.pdf},
  Publisher={ACM},
  Title={Verbal coordination in first person shooter games},
  Type={conference},
  Year={2012},
  Bdsk-Url-1={http://doi.acm.org/10.1145/2145204.2145292}
}

@inproceedings{reilly2011toward,
  Abstract={We reflect on our experiences using an experimental platform for rapidly
    prototyping physical control configurations for multiplayer games. We describe
    how the architecture permits novel forms of collaborative play through the
    combination and configuration of basic tangible/physical building blocks, the
    deep integration between physical and virtual objects, and flexibility in how
    physical and virtual spaces are mapped onto each other. We also identify three
    important limitations of the architecture that became apparent through our
    prototyping efforts.},
  Address={Berlin, Heidelberg},
  Author={Reilly, Derek and Tang, Anthony and Wu, Andy and Mathiasen, Niels and
    Echenique, Andy and Massey, Jonathan and Rouzati, Hafez and Chamoli, Shashank},
  Booktitle={ICEC'11: Proceedings of the 10th international conference on Entertainment
    Computing},
  Date-Modified={2014-01-17 04:39:20 +0000},
  Doi={http://dx.doi.org/10.1007/978-3-642-24500-8_58},
  Isbn={978-3-642-24499-5},
  Location={Vancouver, Canada},
  Pages={428--431},
  Pdfurl={http://hcitang.org/papers/2011-icec2011-twinspace-experiences.pdf},
  Publisher={Springer-Verlag},
  Title={Toward a framework for prototyping physical interfaces in multiplayer
    gaming: twinspace experiences},
  Type={conference},
  Year={2011},
  Bdsk-Url-1={http://dx.doi.org/10.1007/978-3-642-24500-8_58}
}

@inproceedings{sundaresan2011helping,
  Abstract={When purchasing home broadband access from Internet service providers
    (ISPs), users must decide which service plans are most appropriate for their
    needs. Today, ISPs advertise their available service plans using only generic
    upload and download speeds. Unfortunately, these metrics do not always accurately
    reflect the varying performance that home users will experience for a wide
    range of applications. In this paper, we propose that each ISP service plan
    carry a "nutrition label" that conveys more comprehensive information about
    network metrics along many dimensions, including various aspects of throughput,
    latency, loss rate, and jitter. We first justify why these metrics should form
    the basis of a network nutrition label. Then, we demonstrate that current plans
    that are superficially similar with respect to advertised download rates may
    have different performance according to the label metrics. We close with a
    discussion of the challenges involved in presenting a nutrition label to users
    in a way that is both accurate and easy to understand.},
  Address={New York, NY, USA},
  Author={Sundaresan, Srikanth and Feamster, Nick and Teixeira, Renata and Tang,
    Anthony and Edwards, W. Keith and Grinter, Rebecca E. and Chetty, Marshini
    and de Donato, Walter},
  Booktitle={HomeNets '11: Proceedings of the 2nd ACM SIGCOMM workshop on Home
    networks},
  Date-Modified={2014-01-17 04:40:29 +0000},
  Doi={http://doi.acm.org/10.1145/2018567.2018571},
  Isbn={978-1-4503-0798-7},
  Keywords={access networks, broadband networks, BISMark, benchmarking},
  Location={Toronto, Ontario, Canada},
  Pages={13--18},
  Pdfurl={http://hcitang.org/papers/2011-homenets2011-internetnutritionlabels.pdf},
  Publisher={ACM},
  Title={Helping users shop for ISPs with internet nutrition labels},
  Type={conference},
  Year={2011},
  Bdsk-Url-1={http://doi.acm.org/10.1145/2018567.2018571}
}

@inproceedings{wu2011tangible,
  Abstract={In this paper, we introduce approaches to navigating and manipulating
    objects in a Collaborative Virtual Environment (CVE) that engage tangible objects
    and an interactive table interface. We also identify three design concerns
    that are common to physical-virtual connectivity for interaction with CVE systems.
    At last, we propose solutions to these issues within the context of CVEs.},
  Acceptance={32{\%} - 65/203},
  Address={New York, NY, USA},
  Author={Wu, Andy and Reilly, Derek and Tang, Anthony and Mazalek, Ali},
  Booktitle={TEI '11: Proceedings of the fifth international conference on Tangible,
    embedded, and embodied interaction},
  Date-Modified={2014-01-17 04:34:09 +0000},
  Doi={http://doi.acm.org/10.1145/1935701.1935710},
  Isbn={978-1-4503-0478-8},
  Keywords={Tangible User Interface, TUI, HCI, Tabletop, 3D interaction, virtual
    world},
  Location={Funchal, Portugal},
  Pages={37--44},
  Pdfurl={http://hcitang.org/papers/2011-tei2011-tangible-navigation.pdf},
  Publisher={ACM},
  Title={Tangible navigation and object manipulation in virtual environments},
  Type={conference},
  Year={2011},
  Bdsk-Url-1={http://doi.acm.org/10.1145/1935701.1935710}
}

@inproceedings{tang2010vistaco,
  Abstract={As we design tabletop technologies, it is important to also understand
    how they are being used. Many prior researchers have developed visualizations
    of interaction data from their studies to illustrate ideas and concepts. In
    this work, we develop an interactional model of tabletop collaboration, which
    informs the design of VisTACO, an interactive visualization tool for tabletop
    collaboration. Using VisTACO, we can explore the interactions of collaborators
    with the tabletop to identify patterns or unusual spatial behaviours, supporting
    the analysis process. VisTACO helps bridge the gap between observing the use
    of a tabletop system, and understanding users' interactions with the system.},
  Address={New York, NY, USA},
  Author={Tang, Anthony and Pahud, Michel and Carpendale, Sheelagh and Buxton,
    Bill},
  Booktitle={ITS '10: ACM International Conference on Interactive Tabletops and
    Surfaces},
  Date-Modified={2014-01-17 04:42:20 +0000},
  Doi={http://doi.acm.org/10.1145/1936652.1936659},
  Isbn={978-1-4503-0399-6},
  Keywords={tabletop, collaboration, information visualization},
  Location={Saarbr\"{u}cken, Germany},
  Pages={29--38},
  Pdfurl={http://hcitang.org/papers/2010-its2010-vistaco.pdf},
  Publisher={ACM},
  Title={VisTACO: visualizing tabletop collaboration},
  Type={conference},
  Year={2010},
  Bdsk-Url-1={http://doi.acm.org/10.1145/1936652.1936659}
}

@inproceedings{neustaedter2010role,
  Abstract={Applications that provide location-based experiences are an increasingly
    viable design space given the proliferation of GPS-enabled mobile devices.
    However, these applications are in their infancy, and we do not yet know what
    design factors will contribute to their success. For this reason, we have studied
    the well-established location-based experience of geocaching. We report on
    the results of a survey of geocachers along with observations from our own
    in-depth geocaching activities. Our findings illustrate that geocaching permits
    users to create a range of experiences for others within a permeable yet restricted
    culture of norms. Once created, geocaches are maintained by the community of
    geocachers through a well-designed groupware system. Here maintenance acts
    can be performed ``in the small,'' given their lightweight and well-defined
    nature, and become less about maintenance and more about personal participation.
    These findings provide insight into how community and groupware can be leveraged
    to support applications for location-based experiences.},
  Address={New York, NY, USA},
  Author={Neustaedter, Carman and Tang, Anthony and Tejinder, Judge K.},
  Booktitle={CHI '10: Proceedings of the SIGCHI Conference on Human Factors in
    Computing Systems},
  Date-Modified={2014-01-17 04:47:25 +0000},
  Doi={http://doi.acm.org/10.1145/1753326.1753590},
  Isbn={978-1-60558-929-9},
  Keywords={Geocaching, location-based experiences, Global Positioning System (GPS)},
  Location={Atlanta, Georgia, USA},
  Pages={1757--1766},
  Pdfurl={http://hcitang.org/papers/2010-chi2010-geocaching.pdf},
  Publisher={ACM},
  Title={The role of community and groupware in geocache creation and maintenance},
  Type={conference},
  Year={2010},
  Bdsk-Url-1={http://doi.acm.org/10.1145/1753326.1753590}
}

@inproceedings{tang2010threes,
  Abstract={We explore the design of a system for three-way collaboration over
    a shared visual workspace, specifically in how to support three channels of
    communication: person, reference, and task-space. In two studies, we explore
    the implications of extending designs intended for dyadic collaboration to
    three-person groups, and the role of each communication channel. Our studies
    illustrate the utility of multiple configurations of users around a distributed
    workspace, and explore the subtleties of traditional notions of identity, awareness,
    spatial metaphor, and corporeal embodiments as they relate to three-way collaboration.
    },
  Address={New York, NY, USA},
  Author={Tang, Anthony and Pahud, Michel and Inkpen, Kori and Benko, Hrvoje and
    Tang, John C. and Buxton, Bill},
  Booktitle={CSCW '10: Proceedings of the 2010 ACM conference on Computer supported
    cooperative work},
  Date-Modified={2014-01-17 04:46:48 +0000},
  Doi={http://doi.acm.org/10.1145/1718918.1718969},
  Isbn={978-1-60558-795-0},
  Keywords={Shared workspace, tabletop, media space, video-mediated communication},
  Location={Savannah, Georgia, USA},
  Notes={Best Paper Nominee (top 5{\%} of submissions)},
  Pages={271--280},
  Pdfurl={http://hcitang.org/papers/2010-cscw2010-three's-company.pdf},
  Publisher={ACM},
  Title={Three's company: understanding communication channels in three-way distributed
    collaboration},
  Type={conference},
  Year={2010},
  Bdsk-Url-1={http://doi.acm.org/10.1145/1718918.1718969}
}

@inproceedings{tang2009supporting,
  Abstract={In this paper, we explore the practice of using a whiteboard for multiple
    tasks, and specifically how users employ whiteboards to smoothly transition
    between related sets of tasks. Our study underscores several basic, but important
    affordances of whiteboards that support this practice, including visual persistence,
    flexibility of interaction primitives, and their situated physicality. We discuss
    the implications of these findings for the design of large display applications.},
  Address={New York, NY, USA},
  Author={Tang, Anthony and Lanir, Joel and Greenberg, Saul and Fels, Sidney},
  Booktitle={GROUP '09: Proceedings of the ACM 2009 international conference on
    Supporting group work},
  Date-Modified={2014-01-17 04:52:20 +0000},
  Doi={http://doi.acm.org/10.1145/1531674.1531697},
  Isbn={978-1-60558-500-0},
  Keywords={Whiteboard, large display groupware, reflexive CSCW},
  Location={Sanibel Island, Florida, USA},
  Pages={149--158},
  Pdfurl={http://hcitang.org/papers/2009-group2009-transitions.pdf},
  Publisher={ACM},
  Title={Supporting transitions in work: informing large display application design
    by understanding whiteboard use},
  Type={conference},
  Year={2009},
  Bdsk-Url-1={http://doi.acm.org/10.1145/1531674.1531697}
}

@inproceedings{lanir2008multipresenter,
  Abstract={We introduce MultiPresenter, a novel presentation system designed to
    work on very large display spaces (multiple displays or physically large high-resolution
    displays). MultiPresenter allows presenters to organize and present pre-made
    and dynamic presentations that take advantage of a very large display space
    accessed from a personal laptop. Presenters can use the extra space to provide
    long-term persistency of information to the audience. Our design deliberately
    separates content generation (authoring) from the presentation of content.
    We focus on supporting presentation flow and a variety of presentation styles,
    ranging from automated, scripted sequences of pre-made slides to highly dynamic
    ad-hoc, and non-linear content. By providing smooth transition between these
    styles, presenters can easily alter the flow of content during a presentation
    to adapt to an audience or to change emphasis in response to emerging interests.
    We describe our goals, rationale and the design process, providing a detailed
    description of the current version of the system, and discuss our experience
    using it throughout a one-semester first year computer science course},
  Address={New York, NY, USA},
  Author={Lanir, Joel and Booth, Kellogg S. and Tang, Anthony},
  Booktitle={MM '08: Proceedings of the 16th ACM international conference on Multimedia},
  Date-Modified={2014-01-17 05:00:32 +0000},
  Doi={http://doi.acm.org/10.1145/1459359.1459428},
  Isbn={978-1-60558-303-7},
  Keywords={High-resolution displays, Human-Centered Design, Multiple displays,
    Presentations},
  Location={Vancouver, British Columbia, Canada},
  Pages={519--528},
  Pdfurl={http://hcitang.org/papers/2008-mm2008-multipresenter-preprint.pdf},
  Publisher={ACM},
  Title={MultiPresenter: a presentation system for (very) large display surfaces},
  Type={conference},
  Year={2008},
  Bdsk-Url-1={http://doi.acm.org/10.1145/1459359.1459428}
}

@inproceedings{finke2008lessons,
  Abstract={This paper presents the design and deployment of Polar Defence, an
    interactive game for a large public display. We designed this display based
    on a model of ``users'' and their interactions with large public displays in
    public spaces, which we derived from prior work. We conducted a four-day user
    study of this system in a public space to evaluate the game and its impact
    on the surrounding environment. Our analysis showed that the installation successfully
    encouraged participation among strangers, and that its design and deployment
    addressed many of the challenges described by prior research literature. Finally,
    we reflect on this deployment to provide design guidance to other researchers
    building large interactive public displays for public spaces. },
  Address={New York, NY, USA},
  Author={Finke, Matthias and Tang, Anthony and Leung, Rock and Blackstock, Michael},
  Booktitle={DIMEA '08: Proceedings of the 3rd international conference on Digital
    Interactive Media in Entertainment and Arts},
  Date-Modified={2014-01-17 05:02:26 +0000},
  Doi={http://doi.acm.org/10.1145/1413634.1413644},
  Isbn={978-1-60558-248-1},
  Keywords={Interactive large public displays, personal devices, cell phones, short
    messages services (SMS), shared entertainment, gaming, user study},
  Location={Athens, Greece},
  Pages={26--33},
  Pdfurl={http://hcitang.org/papers/2008-dimea2008-lessons-learned.pdf},
  Publisher={ACM},
  Title={Lessons learned: game design for large public displays},
  Type={conference},
  Year={2008},
  Bdsk-Url-1={http://doi.acm.org/10.1145/1413634.1413644}
}

@inproceedings{tang2008exploring,
  Abstract={Video slicing---a variant of slit scanning in photography---extracts
    a scan line from a video frame and successively adds that line to a composite
    image over time. The composite image becomes a time line, where its visual
    patterns reflect changes in a particular area of the video stream. We extend
    this idea of video slicing by allowing users to draw marks anywhere on the
    source video to capture areas of interest. These marks, which we call slit-tears,
    are used in place of a scan line, and the resulting composite timeline image
    provides a much richer visualization of the video data. Depending on how tears
    are placed, they can accentuate motion, small changes, directional movement,
    and relational patterns.},
  Address={New York, NY, USA},
  Author={Tang, Anthony and Greenberg, Saul and Fels, Sidney},
  Booktitle={AVI '08: Proceedings of the working conference on Advanced visual
    interfaces},
  Date-Modified={2014-01-17 04:55:58 +0000},
  Doi={http://doi.acm.org/10.1145/1385569.1385601},
  Isbn={978-1-60558-141-5},
  Keywords={Information visualization, video analysis, video history, timelines},
  Location={Napoli, Italy},
  Pages={191--198},
  Pdfurl={http://hcitang.org/papers/2008-avi2008-slit-tear.pdf},
  Publisher={ACM},
  Title={Exploring video streams using slit-tear visualizations},
  Type={conference},
  Videourl={http://www.youtube.com/watch?v=-kvMth6IpNw},
  Year={2008},
  Bdsk-Url-1={http://doi.acm.org/10.1145/1385569.1385601}
}

@inproceedings{isenberg2008exploratory,
  Abstract={To design information visualization tools for collaborative use, we
    need to understand how teams engage with visualizations during their information
    analysis process. We report on an exploratory study of individuals, pairs,
    and triples engaged in information analysis tasks using paper-based visualizations.
    From our study results, we derive a framework that captures the analysis activities
    of co-located teams and individuals. Comparing this framework with existing
    models of the information analysis process suggests that information visualization
    tools may benefit from providing a flexible temporal flow of analysis actions.},
  Address={New York, NY, USA},
  Author={Isenberg, Petra and Tang, Anthony and Carpendale, Sheelagh},
  Booktitle={CHI '08: Proceedings of the SIGCHI Conference on Human Factors in
    Computing Systems},
  Date-Modified={2014-01-17 05:01:42 +0000},
  Doi={http://doi.acm.org/10.1145/1357054.1357245},
  Isbn={978-1-60558-011-1},
  Keywords={Information Visualization, analysis process, collaboration},
  Location={Florence, Italy},
  Pages={1217--1226},
  Pdfurl={http://hcitang.org/papers/2008-chi2008-exploratory-study-of-visual-information-analysis.pdf},
  Publisher={ACM},
  Title={An exploratory study of visual information analysis},
  Type={conference},
  Year={2008},
  Bdsk-Url-1={http://doi.acm.org/10.1145/1357054.1357245}
}

@inproceedings{tang2008designing,
  Abstract={In this paper, we reflect on the design and deployment process of MAGICBoard,
    a public display deployed in a university setting that solicits the electronic
    votes and opinions of bystanders on trivial but amusing topics. We focus on
    the consequences of our design choices with respect to encouraging bystanders
    to interact with the public display. Bystanders are individuals around the
    large display who may never fully engage with the application itself, but are
    potential contributors to the system. Drawing on our recent experiences with
    MAGICBoard, we present a classification of bystanders, and then discuss three
    design themes relevant to the design of systems for bystander use: graduated
    proximal engagement, lowering barriers for interaction and supporting covert
    engagement. },
  Address={New York, NY, USA},
  Author={Tang, Anthony and Finke, Mattias and Blackstock, Michael and Leung, Rock
    and Deutscher, Meghan and Lea, Rodger},
  Booktitle={CHI '08: Proceedings of the SIGCHI Conference on Human Factors in
    Computing Systems},
  Date-Modified={2014-01-17 04:57:29 +0000},
  Doi={http://doi.acm.org/10.1145/1357054.1357193},
  Isbn={978-1-60558-011-1},
  Keywords={bystanders, large display groupware, large displays, mobile computing,
    sms},
  Location={Florence, Italy},
  Pages={879--882},
  Pdfurl={http://hcitang.org/papers/2008-chi2008-designing-for-bystanders.pdf},
  Publisher={ACM},
  Title={Designing for bystanders: reflections on building a public digital forum},
  Type={conference},
  Year={2008},
  Bdsk-Url-1={http://doi.acm.org/10.1145/1357054.1357193}
}

@inproceedings{wong2009character,
  Abstract={Many online games are played through characters that act out players'
    intentions in the game world. The practice of character sharing -- allowing
    others to use one's characters, or using others' -- is prohibited in many RPGs,
    but anecdotal evidence suggests that the practice is common, and that it may
    play an important role in the game. To shed light on this little-known form
    of collaboration, we carried out a large-scale survey study to investigate
    character sharing in one RPG, World of Warcraft. We analyze and report on 1348
    responses, providing a detailed picture of sharing practices and attitudes.
    We found that character sharing is common (57{\%} of respondents reported sharing)
    and that sharers have a wide variety of motivations and concerns. In addition
    to showing how character sharing works, the study also provides new perspectives
    on several themes in CSCW, including conceptions of sharing, online identity,
    and mediating artifacts.},
  Author={Wong, Nelson and Tang, Anthony and Livingston, Ian and Gutwin, Carl and
    Mandryk, Regan},
  Booktitle={ECSCW 2009: Proceedings of the European Conference on Computer Supported
    Cooperative Work (ECSCW)},
  Date-Modified={2014-01-17 04:51:21 +0000},
  Pages={343--362},
  Pdfurl={http://hcitang.org/papers/2009-ecscw2009-character-sharing.pdf},
  Publisher={Springer London},
  Title={Character sharing in World of Warcraft},
  Type={conference},
  Year={2009}
}

@inproceedings{shoemaker2007shadow,
  Abstract={We introduce Shadow Reaching, an interaction technique that makes use
    of a perspective projection applied to a shadow representation of a user. The
    technique was designed to facilitate manipulation over large distances and
    enhance understanding in collaborative settings. We describe three prototype
    implementations that illustrate the technique, examining the advantages of
    using shadows as an interaction metaphor to support single users and groups
    of collaborating users. Using these prototypes as a design probe, we discuss
    how the three components of the technique (sensing, modeling, and rendering)
    can be accomplished with real (physical) or computed (virtual) shadows, and
    the benefits and drawbacks of each approach.},
  Address={New York, NY, USA},
  Author={Shoemaker, Garth and Tang, Anthony and Booth, Kellogg S.},
  Booktitle={UIST '07: Proceedings of the 20th annual ACM symposium on User interface
    software and technology},
  Date-Modified={2014-01-17 05:04:59 +0000},
  Doi={http://doi.acm.org/10.1145/1294211.1294221},
  Isbn={978-1-59593-679-0},
  Keywords={Large displays, interaction techniques},
  Location={Newport, Rhode Island, USA},
  Pages={53--56},
  Pdfurl={http://hcitang.org/papers/2007-uist2007-shadow-reaching.pdf},
  Publisher={ACM},
  Title={Shadow reaching: a new perspective on interaction for large displays},
  Type={conference},
  Videourl={http://www.youtube.com/watch?v=Su4ZIqxaObo},
  Year={2007},
  Bdsk-Url-1={http://doi.acm.org/10.1145/1294211.1294221}
}

@inproceedings{miyaoku2007cband,
  Abstract={This paper proposed a new visual tag system for enhancing real world
    media interaction using handheld camera devices. This paper also described
    performance evaluations of the prototype, and its applications. C-Band is based
    on a ring with a color pattern code. A C-Band tag can provide a self-contained
    URL, and is flexible enough to allow various aesthetic designs for the tag's
    surface. Furthermore, the tag's structure is useful for building interactive
    techniques. Taken together, these features suggest that C-Band is an effective
    method to build various attractive camera-based media interactions.},
  Address={Berlin, Heidelberg},
  Author={Miyaoku, Kento and Tang, Anthony and Fels, Sidney},
  Booktitle={ICVR'07: Proceedings of the 2nd international conference on Virtual
    reality},
  Date-Modified={2014-01-17 05:07:10 +0000},
  Doi={http://dx.doi.org/10.1007/978-3-540-73335-5_35},
  Isbn={978-3-540-73334-8},
  Keywords={Visual Tag, Color-Difference Signal, Camera, Mobile Terminal},
  Location={Beijing, China},
  Pages={320--328},
  Pdfurl={http://hcitang.org/papers/2007-hcii-c-band.pdf},
  Publisher={Springer-Verlag},
  Title={C-band: a flexible ring tag system for camera-based user interface},
  Type={conference},
  Year={2007},
  Bdsk-Url-1={http://dx.doi.org/10.1007/978-3-540-73335-5_35}
}

article{2006c,
  Author={{\aa}{\textregistered}{\textregistered}{\aa}{\textyen}{\textyen}{\aa}?{\textyen}{\"a}??
    and Tang, A and Fels, S},
  Journal={{\~a}?{\textcurrency}{\~a}?{\textthreesuperior}{\~a}?{\textquestiondown}{\~a}?{\copyright}{\~a}??{\~a}?{\textperiodcentered}{\~a}?{\S}{\~a}?{\textthreesuperior}},
  Pages={3--10},
  Title={C-Band: {\ae}??{\`e}{\guillemotright}?{\~a}??{\~a}?{\guillemotleft}{\~a}?{\copyright}{\~a}?{\textonequarter}{\c{c}}?{\textdegree}{\c{c}}??{\~a}?{\textquestiondown}{\~a}?{\textdegree}{\~a}?{\textperiodcentered}{\~a}?{\textonesuperior}{\~a}??{\~a}??},
  Type={conference},
  Year={2006}
}

@inproceedings{siu2006going,
  Abstract={Email use in the context of everyday work practices, or email flow,
    has not been heavily studied. We present the results of a pair of studies examining
    how users interlace email with their day-to-day, ongoing work processes. We
    demonstrate that our subjects use email as a tool for managing moment-to-moment
    attention and task focus. We also provide a model of this workflow that builds
    upon an existing model by Venolia et al. Finally, we provide specific design
    recommendations to enhance the usability of email clients in support of these
    modes of interaction. },
  Address={New York, NY, USA},
  Author={Siu, Nelson and Iverson, Lee and Tang, Anthony},
  Booktitle={CSCW '06: Proceedings of the 2006 20th anniversary conference on Computer
    supported cooperative work},
  Date-Modified={2014-01-17 05:11:49 +0000},
  Doi={http://doi.acm.org/10.1145/1180875.1180942},
  Isbn={1-59593-249-6},
  Keywords={Email deferral, email flow, task management},
  Location={Banff, Alberta, Canada},
  Pages={441--450},
  Pdfurl={http://hcitang.org/papers/2006-cscw2006-going-with-the-flow.pdf},
  Publisher={ACM},
  Title={Going with the flow: email awareness and task management},
  Type={conference},
  Year={2006},
  Bdsk-Url-1={http://doi.acm.org/10.1145/1180875.1180942}
}

@inproceedings{tang2006collaborative,
  Abstract={Designing collaborative interfaces for tabletops remains difficult
    because we do not fully understand how groups coordinate their actions when
    working collaboratively over tables. We present two observational studies of
    pairs completing independent and shared tasks that investigate collaborative
    coupling, or the manner in which collaborators are involved and occupied with
    each other's work. Our results indicate that individuals frequently and fluidly
    engage and disengage with group activity through several distinct, recognizable
    states with unique characteristics. We describe these states and explore the
    consequences of these states for tabletop interface design.},
  Address={New York, NY, USA},
  Author={Tang, Anthony and Tory, Melanie and Po, Barry and Neumann, Petra and
    Carpendale, Sheelagh},
  Booktitle={CHI '06: Proceedings of the SIGCHI Conference on Human Factors in
    Computing Systems},
  Date-Modified={2014-01-17 05:11:23 +0000},
  Doi={http://doi.acm.org/10.1145/1124772.1124950},
  Isbn={1-59593-372-7},
  Keywords={Collaborative tabletop displays, single display groupware, mixed focus
    collaboration, coordination, coupling},
  Location={Montr{\'e}al, Qu{\'e}bec, Canada},
  Pages={1181--1190},
  Pdfurl={http://hcitang.org/papers/2006-chi2006-collaborative-coupling.pdf},
  Publisher={ACM},
  Title={Collaborative coupling over tabletop displays},
  Type={conference},
  Year={2006},
  Bdsk-Url-1={http://doi.acm.org/10.1145/1124772.1124950}
}

@inproceedings{tang2007videoarms,
  Abstract={Mixed presence groupware (MPG) allows collocated and distributed teams
    to work together on a shared visual workspace. Presence disparity arises in
    MPG because it is harder to maintain awareness of remote collaborators compared
    to collocated collaborators. We examine the role of one's body in collaborative
    work and how it affects presence disparity, articulating four design implications
    for embodiments in mixed presence groupware to mitigate the effects of presence
    disparity: embodiments should provide local feedback; they should visually
    portray people's interaction with the work surface using direct input mechanisms;
    they should display fine-grain movement and postures of hand gestures, and
    they should be positioned within the workspace. We realize and evaluate these
    implications with VideoArms, an embodiment technique that captures and reproduces
    people's arms as they work over large displays. },
  Author={Tang, Anthony and Neustaedter, Carman and Greenberg, Saul},
  Booktitle={People and Computers XX---Engage},
  Date-Modified={2014-01-17 05:03:42 +0000},
  Keywords={consequential communication, embodiments, distributed groupware, gestures,
    mixed presence groupware, single display groupware},
  Pages={85--102},
  Pdfurl={http://hcitang.org/papers/2006-hci2006-videoarms-embodiments-in-mpg.pdf},
  Publisher={Springer London},
  Title={Videoarms: embodiments for mixed presence groupware},
  Type={conference},
  Year={2007}
}

@inproceedings{fels2006investigation,
  Abstract={We explore the impact of tilting the driver's seat according to the
    relative distance and velocity to objects outside the car using a haptic feedback
    chair in a driving simulator. We found that drivers perform best when (1) the
    seat tilts according to relative distance (vs. velocity) to objects outside
    the car and (2) the seat tilts forward (vs. backward) when the driver gets
    closer to a car in front of them. We also found that when visually and cognitively
    distracted, drivers perform better using haptic feedback than without. Our
    results suggest that adding haptic feedback to the car seat may improve driving
    safety and enjoyment by enhancing the driving experience},
  Author={Fels, Sidney and Hausch, Robert and Tang, Anthony},
  Booktitle={Intelligent Transportation Systems Conference, 2006. ITSC'06. IEEE},
  Date-Modified={2014-01-17 05:14:19 +0000},
  Doi={http://dx.doi.org/10.1109/ITSC.2006.1706804},
  Keywords={driver seat; driving safety; driving simulator; haptic feedback chair},
  Organization={IEEE},
  Pages={584--589},
  Title={Investigation of haptic feedback in the driver seat},
  Type={conference},
  Year={2006},
  PdfUrl={http://hcitang.org/papers/2006-itsc2006-haptic-seat.pdf},
  Bdsk-Url-1={http://dx.doi.org/10.1109/ITSC.2006.1706804}
}

@inproceedings{tang2005perceiving,
  Abstract={Visual information overload is a threat to the interpretation of displays
    presenting large data sets or complex application environments. To combat this
    problem, researchers have begun to explore how haptic feedback can be used
    as another means for information transmission. In this paper, we show that
    people can perceive and accurately process haptically rendered ordinal data
    while under cognitive workload. We evaluate three haptic models for rendering
    ordinal data with participants who were performing a taxing visual tracking
    task. The evaluation demonstrates that information rendered by these models
    is perceptually available even when users are visually busy. This preliminary
    research has promising implications for haptic augmentation of visual displays
    for information visualization. },
  Address={New York, NY, USA},
  Author={Tang, Anthony and McLachlan, Peter and Lowe, Karen and Saka, Chalapati
    Rao and MacLean, Karon},
  Booktitle={ICMI '05: Proceedings of the 7th international conference on Multimodal
    interfaces},
  Date-Modified={2014-01-17 05:26:20 +0000},
  Doi={http://doi.acm.org/10.1145/1088463.1088517},
  Isbn={1-59593-028-0},
  Keywords={Haptics, 1-DOF, tangible user interface, graspable user interface,
    haptic perception, multimodal displays, information visualization},
  Location={Torento, Italy},
  Pages={317--324},
  Pdfurl={http://hcitang.org/papers/2005-icmi-haptic-perception.pdf},
  Publisher={ACM},
  Title={Perceiving ordinal data haptically under workload},
  Type={conference},
  Year={2005},
  Bdsk-Url-1={http://doi.acm.org/10.1145/1088463.1088517},
  Notes={Best paper award}
}

@inproceedings{kruger2005fluid,
  Abstract={Previous research has shown that rotation and orientation of items
    plays three major roles during collaboration: comprehension, coordination and
    communication. Based on these roles of orientation and advice from kinesiology
    research, we have designed the Rotate'N Translate (RNT) interaction mechanism,
    which provides integrated control of rotation and translation using only a
    single touch-point for input. We present an empirical evaluation comparing
    RNT to a common rotation mechanism that separates control of rotation and translation.
    Results of this study indicate RNT is more efficient than the separate mechanism
    and better supports the comprehension, coordination and communication roles
    of orientation.},
  Address={New York, NY, USA},
  Author={Kruger, Russell and Carpendale, Sheelagh and Scott, Stacey D. and Tang,
    Anthony},
  Booktitle={CHI '05: Proceedings of the SIGCHI Conference on Human Factors in
    Computing Systems},
  Date-Modified={2014-01-17 05:28:25 +0000},
  Doi={http://doi.acm.org/10.1145/1054972.1055055},
  Isbn={1-58113-998-5},
  Keywords={Fluid interactions, rotation, translation, orientation, roles of orientation,
    tabletop collaboration, communicative gestures},
  Location={Portland, Oregon, USA},
  Pages={601--610},
  Pdfurl={http://hcitang.org/papers/2005-chi2005-rnt.pdf},
  Publisher={ACM},
  Title={Fluid integration of rotation and translation},
  Type={conference},
  Year={2005},
  Bdsk-Url-1={http://doi.acm.org/10.1145/1054972.1055055}
}

@inproceedings{tang2004display,
  Abstract={Mixed Presence Groupware (MPG) supports both co-located and distributed
    participants working over a shared visual workspace. It does this by connecting
    multiple single-display groupware workspaces together through a shared data
    structure. Our implementation and observations of MPG systems exposes two problems.
    The first is display disparity, where connecting heterogeneous tabletop and
    vertical displays introduces issues in how one seats people around the virtual
    table and how one orients work artifacts. The second is presence disparity,
    where a participant's perception of the presence of others is markedly different
    depending on whether a collaborator is co-located or remote. This is likely
    caused by inadequate consequential communication between remote participants,
    which in turn disrupts group collaborative and communication dynamics. To mitigate
    display and presence disparity problems, we determine virtual seating positions
    and replace conventional telepointers with digital arm shadows that extend
    from a person's side of the table to their pointer location.},
  Address={Darlinghurst, Australia, Australia},
  Author={Tang, Anthony and Boyle, Michael and Greenberg, Saul},
  Booktitle={AUIC '04: Proceedings of the fifth conference on Australasian user
    interface},
  Date-Modified={2014-01-17 05:30:58 +0000},
  Location={Dunedin, New Zealand},
  Notes={Superceded by JRPIT article of same title},
  Pages={73--82},
  Publisher={Australian Computer Society, Inc.},
  Title={Display and presence disparity in Mixed Presence Groupware},
  Type={conference},
  Url={http://dl.acm.org/citation.cfm?id=976310.976320},
  PdfUrl={http://hcitang.org/papers/2004-auic2004-display-and-presence-disparity.pdf},
  Year={2004},
  Bdsk-Url-1={http://dl.acm.org/citation.cfm?id=976310.976320}
}

@inproceedings{tang2006surface,
  Abstract={Although we can now augment meeting rooms with large-format digital
    displays (e.g. digital whiteboards or tabletops), successful deployment of
    groupware tools for such environments has been limited. I believe this problem
    stems from a poor understanding of how teams make use of traditional meeting
    room surfaces (e.g. whiteboards, walls, tables) in collaboration; as a consequence,
    our large display groupware applications do not always reflect the general
    expectations users have of large displays, which replace traditional, non-digital
    meeting room surfaces. My research develops a framework for understanding how
    meeting room surfaces are used collaboratively, thereby providing insight into
    application design for digital display surfaces in meeting rooms. },
  Author={Tang, Anthony},
  Booktitle={Conference Companion of the 2006 20th Anniversary Conference on Computer
    Supported Cooperative Work},
  Date-Modified={2014-01-17 05:09:10 +0000},
  Keywords={Large display groupware, meeting room collaboration},
  Pages={43-44},
  Pdfurl={http://hcitang.org/papers/2006-cscw2006-surface-use-in-meeting-room-collaboration.pdf},
  Title={Surface use in meeting room collaboration},
  Type={poster},
  Url={http://hcitang.org/papers/2006-cscw2006-surface-use-in-meeting-room-collaboration-poster.pdf},
  Year={2006},
  Bdsk-Url-1={http://hcitang.org/papers/2006-cscw2006-surface-use-in-meeting-room-collaboration-poster.pdf}
}

@inproceedings{ledo2013onespace,
  Abstract={Video conferencing commonly employs a video portal metaphor to connect
    individuals from remote spaces. In this work, we explore an alternate metaphor,
    a shared depth-mirror, where video images of two spaces are fused into a single
    shared, depth-corrected video space. We realize this metaphor in OneSpace,
    where the space respects virtual spatial relationships between people and objects
    as if all parties were looking at a mirror together. We report preliminary
    observations of OneSpace's use, noting that it encourages cross-site, full-body
    interactions, and that participants employed the depth cues in their interactions.
    Based on these observations, we argue that the depth mirror offers new opportunities
    for shared video interaction.},
  Address={New York, NY, USA},
  Author={Ledo, David and Aseniero, Bon Adriel and Greenberg, Saul and Boring,
    Sebastian and Tang, Anthony},
  Booktitle={CHI EA '13: CHI '13 Extended Abstracts on Human Factors in Computing
    Systems},
  Date-Modified={2014-01-11 05:45:23 +0000},
  Doi={http://doi.acm.org/10.1145/2468356.2468534},
  Isbn={978-1-4503-1952-2},
  Keywords={Video communication; media spaces},
  Location={Paris, France},
  Pages={997--1002},
  Pdfurl={http://hcitang.org/papers/2013-chi2013-wip-onespace.pdf},
  Publisher={ACM},
  Title={OneSpace: shared depth-corrected video interaction},
  Type={poster},
  Year={2013},
  Bdsk-Url-1={http://doi.acm.org/10.1145/2468356.2468534}
}

@inproceedings{tang2006studying,
  Abstract={In this poster, we focus on the use of large vertical surfaces (e.g.walls,
    flipcharts, whiteboards), articulating four unique roles they play in collaboration:
    presentation, ideation, reference, and notice . By understanding these roles,
    we can design interactiontechniques that exploit people's expectations and
    uses of thesesurfaces. As an example, we realize one design idea in Pick-and-
    Point ---a fluid interaction technique that moves content from personal surfaces
    onto large surfaces that recognizes thecollaborative role of large vertical
    surfaces.},
  Author={Tang, Anthony and Parker, J Karen and Lanir, Joel and Booth, KS and Fels,
    Sidney},
  Booktitle={Conference Companion of the 2006 20th Anniversary Conference on Computer
    Supported Cooperative Work},
  Date-Modified={2014-01-17 05:10:53 +0000},
  Keywords={display ecology, large screen display, tabletpc},
  Pages={219-220},
  Pdfurl={http://hcitang.org/papers/2006-cscw2006-studying-surface-use-to-guide-large-display-interaction-design.pdf},
  Title={Studying collaborative surface use to guide large display interaction
    design},
  Type={poster},
  Url={http://hcitang.org/papers/2006-cscw2006-surface-use-in-meeting-room-collaboration-poster.pdf},
  Year={2006},
  Bdsk-Url-1={http://hcitang.org/papers/2006-cscw2006-surface-use-in-meeting-room-collaboration-poster.pdf}
}

@inproceedings{tang2009exploring,
  Abstract={Slit-tear visualizations allow users to selectively visualize pixel
    paths in a video scene. The slit-tear visualization technique is a generalization
    of the traditional photographic slit-scanning and more recent video slicing
    techniques: after a user specifies a pixel path of interest, the system generates
    a timeline that replicates those pixels for each frame in the video. These
    rich visualizations of the video data help users to discover and explore spatio-temporal
    patterns of activity in a video. In this video, we illustrate the use of slit-tear
    visualizations to detect movement and incidence of activity in a video scene,
    accentuate directional motion and small changes in the video, and discover
    patterns of activity between spatially distinct areas of the scene. },
  Address={New York, NY, USA},
  Author={Tang, Anthony and Greenberg, Saul and Fels, Sidney},
  Booktitle={CHI EA '09: CHI '09 Extended Abstracts on Human Factors in Computing
    Systems},
  Date-Modified={2014-01-17 04:53:20 +0000},
  Doi={http://doi.acm.org/10.1145/1520340.1520516},
  Isbn={978-1-60558-247-4},
  Keywords={video analysis, video visualization, video interaction, information
    visualization},
  Location={Boston, MA, USA},
  Notes={Best Research Video Nominee},
  Pages={3509--3510},
  Pdfurl={http://hcitang.org/papers/2009-chi2009-videoshowcase-slittears.pdf},
  Publisher={ACM},
  Title={Exploring video streams using slit-tear visualizations},
  Type={video},
  Videourl={http://hcitang.org/papers/2009-chi2009-videoshowcase-slittears.wmv},
  Year={2009},
  Bdsk-Url-1={http://doi.acm.org/10.1145/1520340.1520516}
}

@inproceedings{tang2004videoarms,
  Abstract={Shared visual workspaces afford collaboration by providing a medium
    that grounds workspace activity, conversation, and gestures. If distributed
    groupware systems designed as shared visual workspaces are to replace or augment
    the physical workspaces of today, they need to naturally support these affordances.
    VideoArms is an embodiment technique for distributed groupware that captures
    body images of collaborators as they work, and transmits them to remote workspaces.
    These body images are then placed in the context of the workspace, thereby
    supporting the transmission of conversational gestures, collaborator identity,
    workspace activity, and complex workspace gestures. The technique uses a purely
    digital approach, allowing for the possibility of different presentation techniques
    (e.g. colour video, shadows, transparent video, outlines, etc.). },
  Author={Tang, Anthony and Neustaedter, Carman and Greenberg, Saul},
  Booktitle={Video Proceedings of CSCW 2004},
  Date-Modified={2014-01-17 05:29:26 +0000},
  Pdfurl={http://hcitang.org/papers/2004-cscw2004-videoarms-video.pdf},
  Title={VideoArms: supporting remote embodiment in groupware},
  Type={video},
  Videourl={http://hcitang.org/papers/2004-cscw2004-videoarms-video.wmv},
  Year={2004}
}

@inproceedings{tang2005dartmail,
  Author={Tang, Anthony and Pattison, Eric and Greenberg, Saul},
  Booktitle={ECSCW 2005: Video Proceedings of European Conference on Computer Supported
    Cooperative Work},
  Date-Modified={2014-01-17 05:27:37 +0000},
  Journal={Video Proceedings of European Conference on Computer Supported Cooperative
    Work},
  Notes={Video and 2-page summary},
  Pdfurl={http://hcitang.org/papers/2005-ecscw2005-dartmail-video.pdf},
  Title={DartMail: Digital information transfer through physical surrogates},
  Type={video},
  Videourl={http://hcitang.org/papers/2005-ecscw2005-dartmail-video.wmv},
  Year={2005}
}

@inproceedings{judge2010bridging,
  Abstract={A typical product development lifecycle for interactive systems starts
    with contextual analysis to guide system design. The challenge however is in
    transitioning from findings about users, their activities, and needs, into
    design requirements, constraints and implications that are directly applicable
    to design. In this workshop, we seek to bring together researchers, designers,
    and practitioners who regularly face the challenge of transitioning from contextual
    analysis to design implications and design practices. Our goal is to foster
    a community in this space, understand the techniques that are being employed
    to move from contextual analysis to design, the challenges that still exist,
    and solutions to overcome them. },
  Author={Judge, Tejinder K and Neustaedter, Carman and Tang, Anthony and Harrison,
    Steve},
  Booktitle={CHI'10 Extended Abstracts on Human Factors in Computing Systems},
  Date-Modified={2014-01-17 04:50:52 +0000},
  Doi={http://doi.acm.org/10.1145/1753846.1754183},
  Keywords={Contextual analysis, design, requirements analysis, gap},
  Organization={ACM},
  Pages={4497--4500},
  Pdfurl={http://hcitang.org/papers/2010-chi2010workshop-bridging-the-gap.pdf},
  Title={Bridging the gap: Moving from contextual analysis to design},
  Type={other},
  Year={2010},
  Bdsk-Url-1={http://doi.acm.org/10.1145/1753846.1754183}
}

@phdthesis{tang2010phd,
  Abstract={Interactive large displays offer exciting new opportunities for collaboration
    and work. Yet, their size will fundamentally change how users expect to use
    and engage with computer applications: a likely reality is that such displays
    will be used by multiple users for multiple simultaneous tasks. These expectations
    demand a new approach for application design beyond the conventional desktop
    application model, where applications are single-user, and intended to support
    a subset of user tasks. In this research, we develop such a framework based
    on the premise that large display applications should support transitions---users'
    desires to shift between multiple tasks and activities. We build this framework
    from models of how traditional large surfaces such as whiteboards are used
    to facilitate multiple tasks---often simultaneously. Based on studies of users'
    whiteboard use, we construct a classification scheme of users' activities with
    whiteboards, and the role of whiteboards in supporting the transitions between
    these activities. From a study of meeting room activity, we then develop a
    classification for collocated activity around traditional surfaces. We further
    develop models of how users' needs change during their use of large display
    applications, exploring two contexts: a digital tabletop application for focused
    collaboration, and a public large display. These studies reveal how users engage
    and disengage with one another during collaborative work, and the dynamic needs
    of bystanders. Next, we design and evaluate a prototype that supports transitions
    between tasks in a scheduling activity using viewing changes. The results demonstrate
    that users transition between related tasks during such activities, and that
    viewing changes can support these transitions. Finally, we describe a design
    space for supporting transitions in large display applications. Taken together,
    the findings of this research illustrate the fundamental need to develop a
    new framework for designing large display applications. This work provides
    a step in this direction by providing rationale and empirical evidence for
    supporting transitions in this framework. In so doing, it suggests that we
    realign designers' efforts from the predominant desktop-centric model of application
    development, and instead to a model that engenders smooth transitions between
    multiple, related activities.},
  Address={2332 Main Mall Vancouver, BC Canada V6T 1Z4},
  Author={Tang, Anthony},
  Date-Modified={2014-01-17 05:25:15 +0000},
  Month={January},
  Pdfurl={http://circle.ubc.ca/bitstream/handle/2429/19394/ubc_2010_spring_tang_anthony.pdf?sequence=1},
  School={University of British Columbia},
  Title={Understanding and supporting transitions with large display applications},
  Type={thesis},
  Url={http://circle.ubc.ca/handle/2429/19394},
  Year={2010},
  Bdsk-Url-1={http://circle.ubc.ca/handle/2429/19394}
}

@mastersthesis{tang2005mscthesis,
  Abstract={In this thesis, I define and explore Mixed Presence Groupware (MPG):
    software that connects distributed groups of collaborators together, allowing
    collocated individuals to work together on a shared display while simultaneously
    working with other, remote groups in the same digital workspace. In my explorations
    of this new class of groupware, I articulate a problem unique to MPG workspaces
    called presence disparity, where collaborators focus their collaborative energies
    toward collocated collaborators while ignoring their remote counterparts. I
    propose that the root cause of this problem is the poor representational properties
    of embodiments for remote collaborators, and develop a theory about embodiments
    for MPG workspaces. I present a video-based embodiment technique called VideoArms
    that addresses the presence disparity problem by following the design guidelines
    set out by the theory. Finally, I evaluate this embodiment technique, demonstrating
    and critiquing its effectiveness in mitigating presence disparity.},
  Address={2500 University Dr NW, Calgary AB, Canada T2N 1N4},
  Author={Tang, Anthony},
  Date-Modified={2014-01-17 05:24:45 +0000},
  Month={January},
  School={University of Calgary},
  Title={Embodiments in Mixed Presence Groupware},
  Type={thesis},
  Year={2005}
}

@inproceedings{rahman2014headaches,
  author={Rahman, S. M. Waliur and Bhaskar, Rahul Kamal and Maurer, Frank and Tang,
    Anthony},
  year={2014},
  title={Supporting Chronic Headache Patientswith Visual Analytics},
  abstract={Usually chronic headache patients are advised by their care providers
    to track their headache episodes in apaper or electronic diary. These diaries
    are primarilyused for information extraction by clinicians to prepareproper
    treatment plan. Patients are generallydependent on clinician?s advices to improve
    theirconditions. However, we hypothesize that with help ofvisual trends and
    analyses of chronic conditions as aform of personal informatics, patients will
    beempowered to manage their own conditions. We propose innovative analytics
    based interactivevisualizations revealing hidden chronic patterns afteranalyzing
    limitations of previous work in this area anddemonstrate how these visualizations
    can help patientsby providing meaningful insights. We intend to carryout qualitative
    research involving real chronic patients to verify our hypothesis},
  booktitle={PVA 2014: A Personal Perspective on Visualization and Visual Analytics
    - Workshop at DIS 2014},
  editor={Sheelagh Carpendale and Melanie Tory and Anthony Tang},
  pdfurl={http://hcitang.org/papers/2014-dis2014workshop-chronic-headaches.pdf},
  type={workshop}
}

@inproceedings{payne2014physviz,
  author={Payne, Jennifer and Carpendale, Sheelagh and Tang, Anthony},
  year={2014},
  title={Physical Visualization and Personal Visual Analytics},
  abstract={Personal data is increasing in both volume and variety. Personal visual
    analytics (PVA) can help us to make use of such data. How might physical visualizations
    serve in this context? Such representations of data can be aesthetically pleasing
    and may feel less task-like; in some situations, physical visualizations also
    improve information retrieval over screen-based representations. },
  booktitle={PVA 2014: A Personal Perspective on Visualization and Visual Analytics
    - Workshop at DIS 2014},
  editor={Sheelagh Carpendale and Melanie Tory and Anthony Tang},
  type={workshop},
}

@inproceedings{aseniero2014river,
  author={Aseniero, Bon Adriel and Tang, Anthony and Carpendale, Sheelagh},
  title={River: Using Personalisation to Support Reflection on Personal Activities},
  abstract={Tools that help us track and log activities ? a class of tools broadly
    termed personal informatics, are gaining prevalence in both the marketplace
    (e.g. FitBit, Nike) and in the research space. These tools collect data about
    a person?s physical activity but leave out contextual data which could be valuable
    for reflection. To address this, we look at other common practices involving
    the logging of activities such as day-planners and diaries. We distil previous
    research to articulate four design considerations to support reflection on
    activities, and realised these in a work-in-progress web-based personal informatics
    tool ?River. },
  booktitle={PVA 2014: A Personal Perspective on Visualization and Visual Analytics
    - Workshop at DIS 2014},
  editor={Sheelagh Carpendale and Melanie Tory and Anthony Tang},
  pdfurl={http://hcitang.org/papers/2014-dis2014workshop-river.pdf},
  type={workshop},
  year={2014}
}

@inproceedings{carpendale2014pvaworkshop,
  author={Carpendale, Sheelagh and Tory, Melanie and Tang, Anthony},
  year={2014},
  title={A Personal Perspective on Visualization and Visual Analytics},
  abstract={Data surrounds each and every one of us in our daily lives, ranging
    from logs of exercise and diet, to information about our home energy use, to
    archives of our interactions with others on social media, to online resources
    pertaining to our hobbies and interests. There is enormous potential for us
    use this data to gain insight and knowledge about ourselves and our communities.
    However, designing and applying visualization and visual analytics in our personal
    lives brings a unique set of design challenges. If these tools belong in our
    personal lives, work type criteria such as efficiency may no longer apply.
    In this workshop we will identify and explore research directions and design
    criteria for personal visualization and personal visual analytics. Our goal
    is to call research attention to these areas, to engage the design community
    in this timely and growing field, and to establish a community and common vision
    for researchers and practitioners working in this space.},
  booktitle={DIS 2014 Companion: Proceedings of the 2014 Companion Publication
    on Designing Interactive Systems},
  publisher={ACM},
  pages={223-225},
  doi={http://doi.acm.org/10.1145/2598784.2598806},
  pdfurl={http://hcitang.org/papers/2014-dis2014workshop-pva-workshop.pdf}
}

